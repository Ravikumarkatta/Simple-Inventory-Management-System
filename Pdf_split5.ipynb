{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravikumarkatta/Simple-Inventory-Management-System/blob/main/Pdf_split5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb1I1RptmEiu",
        "outputId": "bd2d3685-b482-4a6d-d709-d2c1c4cd614c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n",
            "✅ Vertical Line Detector loaded!\n",
            "👤 User: __main__\n",
            "🕐 Current time: 2025-08-08 12:13:25 UTC\n",
            "\n",
            "📏 Specialized for PDFs with vertical divider lines!\n",
            "\n",
            "🎯 Available functions:\n",
            "• test_line_detection() - Analyze your PDF's vertical lines\n",
            "• main_line_based_split() - Split using detected lines\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 🎯 VERTICAL LINE DETECTOR - Perfect split using actual PDF lines\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List, Dict\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import fitz  # PyMuPDF\n",
        "    from tqdm.auto import tqdm\n",
        "    from google.colab import files\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display, HTML, clear_output\n",
        "    print(\"✅ All imports successful!\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class VerticalLineDetector:\n",
        "    \"\"\"Detects vertical lines in PDF for perfect split positioning\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.debug_mode = True\n",
        "        print(\"📏 Vertical Line Detector initialized!\")\n",
        "\n",
        "    def detect_vertical_lines(self, pdf_path: str, sample_pages: int = 10) -> Dict:\n",
        "        \"\"\"\n",
        "        Detect vertical lines in PDF pages to find exact split positions\n",
        "\n",
        "        Returns:\n",
        "        - detected_lines: List of vertical line positions\n",
        "        - optimal_split: Best split position based on detected lines\n",
        "        - confidence: How confident we are in the detection\n",
        "        - line_consistency: How consistent lines are across pages\n",
        "        \"\"\"\n",
        "\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        try:\n",
        "            total_pages = len(doc)\n",
        "            sample_pages = min(sample_pages, total_pages)\n",
        "\n",
        "            print(f\"📏 Analyzing {sample_pages} pages for vertical lines...\")\n",
        "\n",
        "            all_vertical_lines = []\n",
        "            page_analyses = []\n",
        "\n",
        "            for page_num in range(sample_pages):\n",
        "                page = doc[page_num]\n",
        "\n",
        "                # Method 1: Drawing/Path Detection\n",
        "                lines_from_paths = self._detect_lines_from_paths(page)\n",
        "\n",
        "                # Method 2: Vector Graphics Detection\n",
        "                lines_from_vectors = self._detect_lines_from_vectors(page)\n",
        "\n",
        "                # Method 3: Text-based Line Detection (like \"|\" characters)\n",
        "                lines_from_text = self._detect_lines_from_text(page)\n",
        "\n",
        "                # Combine all detected lines for this page\n",
        "                page_lines = []\n",
        "                page_lines.extend(lines_from_paths)\n",
        "                page_lines.extend(lines_from_vectors)\n",
        "                page_lines.extend(lines_from_text)\n",
        "\n",
        "                # Remove duplicates and sort\n",
        "                page_lines = list(set(page_lines))\n",
        "                page_lines.sort()\n",
        "\n",
        "                page_analysis = {\n",
        "                    'page_num': page_num,\n",
        "                    'lines': page_lines,\n",
        "                    'page_width': page.rect.width,\n",
        "                    'page_height': page.rect.height,\n",
        "                    'methods': {\n",
        "                        'paths': len(lines_from_paths),\n",
        "                        'vectors': len(lines_from_vectors),\n",
        "                        'text': len(lines_from_text)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                page_analyses.append(page_analysis)\n",
        "                all_vertical_lines.extend(page_lines)\n",
        "\n",
        "                if self.debug_mode:\n",
        "                    print(f\"📄 Page {page_num + 1}: Found {len(page_lines)} vertical lines\")\n",
        "                    if page_lines:\n",
        "                        ratios = [line / page.rect.width for line in page_lines]\n",
        "                        print(f\"   • Line positions: {[f'{r:.1%}' for r in ratios]}\")\n",
        "\n",
        "            # Analyze all detected lines\n",
        "            final_analysis = self._analyze_detected_lines(all_vertical_lines, page_analyses)\n",
        "\n",
        "            return final_analysis\n",
        "\n",
        "        finally:\n",
        "            doc.close()\n",
        "\n",
        "    def _detect_lines_from_paths(self, page) -> List[float]:\n",
        "        \"\"\"Detect vertical lines from PDF drawing paths\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            # Get page drawings/paths\n",
        "            drawings = page.get_drawings()\n",
        "\n",
        "            for drawing in drawings:\n",
        "                items = drawing.get(\"items\", [])\n",
        "\n",
        "                for item in items:\n",
        "                    if item[0] == \"l\":  # Line drawing command\n",
        "                        # item format: (\"l\", point1, point2)\n",
        "                        if len(item) >= 3:\n",
        "                            p1, p2 = item[1], item[2]\n",
        "\n",
        "                            # Check if it's a vertical line (same x-coordinate)\n",
        "                            if abs(p1.x - p2.x) < 2:  # Allow 2-pixel tolerance\n",
        "                                # Check if it's long enough to be a page divider\n",
        "                                line_length = abs(p2.y - p1.y)\n",
        "                                if line_length > page.rect.height * 0.5:  # At least 50% of page height\n",
        "                                    vertical_lines.append(p1.x)\n",
        "\n",
        "                    elif item[0] == \"re\":  # Rectangle (might be a thin vertical rectangle)\n",
        "                        if len(item) >= 2:\n",
        "                            rect = item[1]\n",
        "                            # Check for thin vertical rectangles\n",
        "                            if rect.width <= 3 and rect.height > page.rect.height * 0.3:\n",
        "                                vertical_lines.append(rect.x0 + rect.width / 2)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Path detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _detect_lines_from_vectors(self, page) -> List[float]:\n",
        "        \"\"\"Detect lines from vector graphics elements\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            # Convert page to SVG to analyze vector elements\n",
        "            svg_text = page.get_svg_image()\n",
        "\n",
        "            # Simple SVG line detection\n",
        "            import re\n",
        "\n",
        "            # Look for vertical line patterns in SVG\n",
        "            # Pattern: <line x1=\"x\" y1=\"y1\" x2=\"x\" y2=\"y2\" ... /> where x1 ≈ x2\n",
        "            line_pattern = r'<line[^>]*x1=\"([^\"]*)\"[^>]*y1=\"([^\"]*)\"[^>]*x2=\"([^\"]*)\"[^>]*y2=\"([^\"]*)\"[^>]*/?>'\n",
        "\n",
        "            matches = re.findall(line_pattern, svg_text)\n",
        "\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    x1, y1, x2, y2 = map(float, match)\n",
        "\n",
        "                    # Check if it's vertical (x1 ≈ x2)\n",
        "                    if abs(x1 - x2) < 2:\n",
        "                        # Check if it's long enough\n",
        "                        line_length = abs(y2 - y1)\n",
        "                        if line_length > page.rect.height * 0.3:\n",
        "                            vertical_lines.append(x1)\n",
        "\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "            # Also look for <rect> elements that might be vertical lines\n",
        "            rect_pattern = r'<rect[^>]*x=\"([^\"]*)\"[^>]*y=\"([^\"]*)\"[^>]*width=\"([^\"]*)\"[^>]*height=\"([^\"]*)\"[^>]*/?>'\n",
        "\n",
        "            rect_matches = re.findall(rect_pattern, svg_text)\n",
        "\n",
        "            for match in rect_matches:\n",
        "                try:\n",
        "                    x, y, width, height = map(float, match)\n",
        "\n",
        "                    # Check for thin vertical rectangles\n",
        "                    if width <= 3 and height > page.rect.height * 0.3:\n",
        "                        vertical_lines.append(x + width / 2)\n",
        "\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Vector detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _detect_lines_from_text(self, page) -> List[float]:\n",
        "        \"\"\"Detect vertical lines from text characters like |, ǀ, ⏐\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            # Get text with positions\n",
        "            text_dict = page.get_text(\"dict\")\n",
        "\n",
        "            # Characters that might represent vertical lines\n",
        "            line_chars = ['|', '┃', '┋', '┇', '┆', '│', '║', 'ǀ', '⏐', 'ǁ']\n",
        "\n",
        "            for block in text_dict.get(\"blocks\", []):\n",
        "                if \"lines\" in block:\n",
        "                    for line in block[\"lines\"]:\n",
        "                        for span in line.get(\"spans\", []):\n",
        "                            text = span.get(\"text\", \"\")\n",
        "                            bbox = span.get(\"bbox\", [0, 0, 0, 0])\n",
        "\n",
        "                            # Check if this span contains line characters\n",
        "                            for char in line_chars:\n",
        "                                if char in text:\n",
        "                                    # Check if it's positioned like a page divider\n",
        "                                    char_x = (bbox[0] + bbox[2]) / 2\n",
        "                                    char_y_span = bbox[3] - bbox[1]\n",
        "\n",
        "                                    # If the character spans a good portion of the page height\n",
        "                                    if char_y_span > 20 or text.count(char) > 5:\n",
        "                                        vertical_lines.append(char_x)\n",
        "\n",
        "            # Also look for repeated pipe characters in a vertical column\n",
        "            blocks = page.get_text(\"dict\").get(\"blocks\", [])\n",
        "\n",
        "            # Group text by similar x-coordinates\n",
        "            x_groups = {}\n",
        "\n",
        "            for block in blocks:\n",
        "                if \"lines\" in block:\n",
        "                    for line in block[\"lines\"]:\n",
        "                        for span in line.get(\"spans\", []):\n",
        "                            text = span.get(\"text\", \"\").strip()\n",
        "                            if any(char in text for char in line_chars):\n",
        "                                bbox = span.get(\"bbox\", [0, 0, 0, 0])\n",
        "                                x_pos = round((bbox[0] + bbox[2]) / 2)\n",
        "\n",
        "                                if x_pos not in x_groups:\n",
        "                                    x_groups[x_pos] = []\n",
        "                                x_groups[x_pos].append(text)\n",
        "\n",
        "            # Check for x-positions with multiple line characters\n",
        "            for x_pos, texts in x_groups.items():\n",
        "                line_char_count = sum(sum(text.count(char) for char in line_chars) for text in texts)\n",
        "                if line_char_count >= 3:  # At least 3 line characters in this column\n",
        "                    vertical_lines.append(float(x_pos))\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Text-based line detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _analyze_detected_lines(self, all_lines: List[float], page_analyses: List[Dict]) -> Dict:\n",
        "        \"\"\"Analyze all detected lines to find the best split position\"\"\"\n",
        "\n",
        "        if not all_lines:\n",
        "            return {\n",
        "                'optimal_split': 0.5,\n",
        "                'confidence': 0.1,\n",
        "                'detected_lines': [],\n",
        "                'method': 'fallback',\n",
        "                'line_consistency': 0.0\n",
        "            }\n",
        "\n",
        "        # Get page width (use from first page)\n",
        "        page_width = page_analyses[0]['page_width'] if page_analyses else 595  # Default A4 width\n",
        "\n",
        "        # Convert to ratios\n",
        "        line_ratios = [line / page_width for line in all_lines if 0.1 <= line / page_width <= 0.9]\n",
        "\n",
        "        if not line_ratios:\n",
        "            return {\n",
        "                'optimal_split': 0.5,\n",
        "                'confidence': 0.1,\n",
        "                'detected_lines': [],\n",
        "                'method': 'fallback',\n",
        "                'line_consistency': 0.0\n",
        "            }\n",
        "\n",
        "        # Cluster similar line positions (within 5%)\n",
        "        clusters = []\n",
        "        line_ratios.sort()\n",
        "\n",
        "        for ratio in line_ratios:\n",
        "            # Find if this ratio belongs to an existing cluster\n",
        "            added_to_cluster = False\n",
        "            for cluster in clusters:\n",
        "                if any(abs(ratio - existing_ratio) <= 0.05 for existing_ratio in cluster):\n",
        "                    cluster.append(ratio)\n",
        "                    added_to_cluster = True\n",
        "                    break\n",
        "\n",
        "            if not added_to_cluster:\n",
        "                clusters.append([ratio])\n",
        "\n",
        "        # Find the most consistent cluster (most occurrences)\n",
        "        best_cluster = max(clusters, key=len)\n",
        "        optimal_split = sum(best_cluster) / len(best_cluster)  # Average of cluster\n",
        "\n",
        "        # Calculate confidence based on:\n",
        "        # 1. How many times this line appears\n",
        "        # 2. How consistent it is across pages\n",
        "        # 3. How many different detection methods found it\n",
        "\n",
        "        line_frequency = len(best_cluster)\n",
        "        total_pages = len(page_analyses)\n",
        "        frequency_confidence = min(1.0, line_frequency / total_pages)\n",
        "\n",
        "        # Check consistency across detection methods\n",
        "        method_count = 0\n",
        "        for page_analysis in page_analyses:\n",
        "            methods = page_analysis['methods']\n",
        "            if any(methods.values()):\n",
        "                method_count += 1\n",
        "\n",
        "        method_confidence = min(1.0, method_count / total_pages)\n",
        "\n",
        "        # Calculate how tight the cluster is (consistency)\n",
        "        if len(best_cluster) > 1:\n",
        "            cluster_tightness = 1 - (max(best_cluster) - min(best_cluster))\n",
        "        else:\n",
        "            cluster_tightness = 1.0\n",
        "\n",
        "        final_confidence = (frequency_confidence + method_confidence + cluster_tightness) / 3\n",
        "\n",
        "        return {\n",
        "            'optimal_split': optimal_split,\n",
        "            'confidence': final_confidence,\n",
        "            'detected_lines': all_lines,\n",
        "            'line_ratios': line_ratios,\n",
        "            'clusters': clusters,\n",
        "            'best_cluster': best_cluster,\n",
        "            'method': 'vertical_line_detection',\n",
        "            'line_consistency': cluster_tightness,\n",
        "            'frequency': line_frequency,\n",
        "            'pages_analyzed': total_pages,\n",
        "            'detection_summary': {\n",
        "                'total_lines_found': len(all_lines),\n",
        "                'valid_ratios': len(line_ratios),\n",
        "                'clusters_found': len(clusters),\n",
        "                'best_cluster_size': len(best_cluster)\n",
        "            }\n",
        "        }\n",
        "\n",
        "class LineBasedPDFSplitter:\n",
        "    \"\"\"PDF Splitter using vertical line detection\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.detector = VerticalLineDetector()\n",
        "        print(\"📏 Line-Based PDF Splitter initialized!\")\n",
        "\n",
        "    def split_using_detected_lines(self, input_path: str, output_path: str) -> bool:\n",
        "        \"\"\"Split PDF using detected vertical lines\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Step 1: Detect vertical lines\n",
        "            print(\"📏 Step 1: Detecting vertical lines...\")\n",
        "            line_analysis = self.detector.detect_vertical_lines(input_path)\n",
        "\n",
        "            optimal_ratio = line_analysis['optimal_split']\n",
        "            confidence = line_analysis['confidence']\n",
        "\n",
        "            print(f\"\\n📊 Line Detection Results:\")\n",
        "            print(f\"   • Optimal split position: {optimal_ratio:.1%}\")\n",
        "            print(f\"   • Detection confidence: {confidence:.1%}\")\n",
        "            print(f\"   • Line consistency: {line_analysis['line_consistency']:.1%}\")\n",
        "            print(f\"   • Total lines found: {line_analysis['detection_summary']['total_lines_found']}\")\n",
        "            print(f\"   • Best cluster size: {line_analysis['detection_summary']['best_cluster_size']}\")\n",
        "\n",
        "            if confidence < 0.3:\n",
        "                print(\"⚠️ Low confidence in line detection. Results may not be optimal.\")\n",
        "            elif confidence > 0.8:\n",
        "                print(\"🎯 High confidence! Line detection is very reliable.\")\n",
        "\n",
        "            # Step 2: Apply the split\n",
        "            print(f\"\\n✂️ Step 2: Splitting at {optimal_ratio:.1%}...\")\n",
        "\n",
        "            input_doc = fitz.open(input_path)\n",
        "            output_doc = fitz.open()\n",
        "\n",
        "            page_count = len(input_doc)\n",
        "            success_count = 0\n",
        "\n",
        "            with tqdm(total=page_count, desc=\"📄 Line-Based Splitting\") as pbar:\n",
        "                for page_num in range(page_count):\n",
        "                    try:\n",
        "                        page = input_doc[page_num]\n",
        "                        rect = page.rect\n",
        "\n",
        "                        # Apply the detected split position\n",
        "                        split_pos = rect.width * optimal_ratio\n",
        "\n",
        "                        # Left half\n",
        "                        left_clip = fitz.Rect(0, 0, split_pos, rect.height)\n",
        "                        left_page = output_doc.new_page(width=split_pos, height=rect.height)\n",
        "                        left_page.show_pdf_page(fitz.Rect(0, 0, split_pos, rect.height),\n",
        "                                               input_doc, page_num, clip=left_clip)\n",
        "\n",
        "                        # Right half\n",
        "                        right_clip = fitz.Rect(split_pos, 0, rect.width, rect.height)\n",
        "                        right_page = output_doc.new_page(width=rect.width - split_pos, height=rect.height)\n",
        "                        right_page.show_pdf_page(fitz.Rect(0, 0, rect.width - split_pos, rect.height),\n",
        "                                                input_doc, page_num, clip=right_clip)\n",
        "\n",
        "                        success_count += 1\n",
        "                        pbar.update(1)\n",
        "\n",
        "                    except Exception as page_error:\n",
        "                        print(f\"⚠️ Page {page_num + 1} error: {page_error}\")\n",
        "                        continue\n",
        "\n",
        "            # Step 3: Save\n",
        "            print(\"💾 Step 3: Saving line-based split...\")\n",
        "\n",
        "            try:\n",
        "                output_doc.save(output_path, garbage=4, deflate=True)\n",
        "\n",
        "                # Results\n",
        "                output_size = os.path.getsize(output_path) / (1024 * 1024)\n",
        "                created_pages = len(output_doc)\n",
        "\n",
        "                print(f\"\\n🎉 Line-Based Split Complete!\")\n",
        "                print(f\"📄 Created: {created_pages} pages from {page_count} original\")\n",
        "                print(f\"📁 Size: {output_size:.2f} MB\")\n",
        "                print(f\"🎯 Success rate: {success_count/page_count:.1%}\")\n",
        "                print(f\"📏 Split position: {optimal_ratio:.1%} (based on detected vertical lines)\")\n",
        "\n",
        "                return True\n",
        "\n",
        "            except Exception as save_error:\n",
        "                print(f\"❌ Save error: {save_error}\")\n",
        "                return False\n",
        "\n",
        "            finally:\n",
        "                input_doc.close()\n",
        "                output_doc.close()\n",
        "                gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "            return False\n",
        "\n",
        "def test_line_detection():\n",
        "    \"\"\"Test vertical line detection on your PDF\"\"\"\n",
        "\n",
        "    print(\"📏 VERTICAL LINE DETECTION TEST\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Find PDF\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith('SMART_')]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found.\")\n",
        "        return\n",
        "\n",
        "    pdf_file = pdf_files[0]\n",
        "    print(f\"📁 Testing: {pdf_file}\")\n",
        "\n",
        "    # Create detector\n",
        "    detector = VerticalLineDetector()\n",
        "\n",
        "    # Detect lines\n",
        "    analysis = detector.detect_vertical_lines(pdf_file, sample_pages=10)\n",
        "\n",
        "    # Show detailed results\n",
        "    print(f\"\\n📊 DETAILED RESULTS:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Optimal split position: {analysis['optimal_split']:.1%}\")\n",
        "    print(f\"Detection confidence: {analysis['confidence']:.1%}\")\n",
        "    print(f\"Line consistency: {analysis['line_consistency']:.1%}\")\n",
        "    print(f\"Total lines detected: {len(analysis['detected_lines'])}\")\n",
        "\n",
        "    if analysis['line_ratios']:\n",
        "        print(f\"\\nAll detected line positions:\")\n",
        "        for i, ratio in enumerate(analysis['line_ratios']):\n",
        "            print(f\"  Line {i+1}: {ratio:.1%}\")\n",
        "\n",
        "    if analysis['clusters']:\n",
        "        print(f\"\\nLine clusters found:\")\n",
        "        for i, cluster in enumerate(analysis['clusters']):\n",
        "            avg_pos = sum(cluster) / len(cluster)\n",
        "            print(f\"  Cluster {i+1}: {avg_pos:.1%} (appears {len(cluster)} times)\")\n",
        "\n",
        "    print(f\"\\n🎯 RECOMMENDATION:\")\n",
        "    print(f\"Split at {analysis['optimal_split']:.1%} with {analysis['confidence']:.1%} confidence\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "def main_line_based_split():\n",
        "    \"\"\"Main function using line detection\"\"\"\n",
        "\n",
        "    print(\"📏 LINE-BASED PDF SPLITTER\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"🎯 Perfect for PDFs with vertical divider lines\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Find PDF\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith('SMART_')]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found.\")\n",
        "        return\n",
        "\n",
        "    pdf_file = pdf_files[0]\n",
        "\n",
        "    # Create splitter\n",
        "    splitter = LineBasedPDFSplitter()\n",
        "\n",
        "    # Generate output name\n",
        "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "    output_file = f\"LINE_SPLIT_{Path(pdf_file).stem}_{timestamp}.pdf\"\n",
        "\n",
        "    # Split using line detection\n",
        "    if splitter.split_using_detected_lines(pdf_file, output_file):\n",
        "        try:\n",
        "            files.download(output_file)\n",
        "            print(\"✅ Download successful!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Download failed: {e}\")\n",
        "\n",
        "print(\"✅ Vertical Line Detector loaded!\")\n",
        "print(f\"👤 User: {__name__ if '__name__' in globals() else 'Ravi-katta-dev'}\")\n",
        "print(f\"🕐 Current time: 2025-08-08 12:13:25 UTC\")\n",
        "print(\"\\n📏 Specialized for PDFs with vertical divider lines!\")\n",
        "print(\"\\n🎯 Available functions:\")\n",
        "print(\"• test_line_detection() - Analyze your PDF's vertical lines\")\n",
        "print(\"• main_line_based_split() - Split using detected lines\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GclEIcwNI06o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🎯 COMPLETE INTELLIGENT PDF SPLITTER - Full Featured Solution\n",
        "# =============================================================================\n",
        "# Author: Advanced PDF Processing System\n",
        "# Date: 2025-08-08 12:18:45 UTC\n",
        "# User: Ravi-katta-dev\n",
        "# Version: 4.0 - Complete Solution\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import zipfile\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List, Dict, Any\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import fitz  # PyMuPDF\n",
        "    from tqdm.auto import tqdm\n",
        "    from google.colab import files\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display, HTML, clear_output\n",
        "    print(\"✅ All imports successful!\")\n",
        "    print(f\"🕐 Session started: 2025-08-08 12:18:45 UTC\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "    print(\"Please install required packages:\")\n",
        "    print(\"!pip install PyMuPDF tqdm ipywidgets\")\n",
        "    raise\n",
        "\n",
        "class CompletePDFSplitter:\n",
        "    \"\"\"Complete PDF Splitter with all advanced features\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.processed_files = []\n",
        "        self.debug_mode = True\n",
        "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        print(f\"🎯 Complete PDF Splitter v4.0 initialized!\")\n",
        "        print(f\"📱 Session ID: {self.session_id}\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 📏 VERTICAL LINE DETECTION SYSTEM\n",
        "    # =============================================================================\n",
        "\n",
        "    def detect_vertical_lines(self, pdf_path: str, sample_pages: int = 10) -> Dict:\n",
        "        \"\"\"Detect vertical lines in PDF for exact split positioning\"\"\"\n",
        "\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        try:\n",
        "            total_pages = len(doc)\n",
        "            sample_pages = min(sample_pages, total_pages)\n",
        "\n",
        "            print(f\"📏 Analyzing {sample_pages} pages for vertical lines...\")\n",
        "\n",
        "            all_vertical_lines = []\n",
        "            page_analyses = []\n",
        "\n",
        "            for page_num in range(sample_pages):\n",
        "                page = doc[page_num]\n",
        "\n",
        "                # Multi-method line detection\n",
        "                lines_from_paths = self._detect_lines_from_paths(page)\n",
        "                lines_from_vectors = self._detect_lines_from_vectors(page)\n",
        "                lines_from_text = self._detect_lines_from_text(page)\n",
        "                lines_from_images = self._detect_lines_from_images(page)\n",
        "\n",
        "                # Combine all methods\n",
        "                page_lines = []\n",
        "                page_lines.extend(lines_from_paths)\n",
        "                page_lines.extend(lines_from_vectors)\n",
        "                page_lines.extend(lines_from_text)\n",
        "                page_lines.extend(lines_from_images)\n",
        "\n",
        "                # Remove duplicates and filter\n",
        "                page_lines = self._filter_and_clean_lines(page_lines, page.rect.width)\n",
        "\n",
        "                page_analysis = {\n",
        "                    'page_num': page_num + 1,\n",
        "                    'lines': page_lines,\n",
        "                    'page_width': page.rect.width,\n",
        "                    'page_height': page.rect.height,\n",
        "                    'methods_count': {\n",
        "                        'paths': len(lines_from_paths),\n",
        "                        'vectors': len(lines_from_vectors),\n",
        "                        'text': len(lines_from_text),\n",
        "                        'images': len(lines_from_images)\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                page_analyses.append(page_analysis)\n",
        "                all_vertical_lines.extend(page_lines)\n",
        "\n",
        "                if self.debug_mode:\n",
        "                    print(f\"📄 Page {page_num + 1}: Found {len(page_lines)} vertical lines\")\n",
        "                    if page_lines:\n",
        "                        ratios = [line / page.rect.width for line in page_lines]\n",
        "                        print(f\"   • Positions: {[f'{r:.1%}' for r in ratios[:5]]}\")\n",
        "\n",
        "            # Analyze all detected lines\n",
        "            final_analysis = self._analyze_all_detected_lines(all_vertical_lines, page_analyses)\n",
        "\n",
        "            return final_analysis\n",
        "\n",
        "        finally:\n",
        "            doc.close()\n",
        "\n",
        "    def _detect_lines_from_paths(self, page) -> List[float]:\n",
        "        \"\"\"Method 1: Detect lines from PDF drawing paths\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            drawings = page.get_drawings()\n",
        "\n",
        "            for drawing in drawings:\n",
        "                items = drawing.get(\"items\", [])\n",
        "\n",
        "                for item in items:\n",
        "                    if item[0] == \"l\":  # Line command\n",
        "                        if len(item) >= 3:\n",
        "                            p1, p2 = item[1], item[2]\n",
        "\n",
        "                            # Check for vertical line\n",
        "                            if abs(p1.x - p2.x) < 3:  # Tolerance for vertical\n",
        "                                line_length = abs(p2.y - p1.y)\n",
        "                                if line_length > page.rect.height * 0.3:\n",
        "                                    vertical_lines.append(p1.x)\n",
        "\n",
        "                    elif item[0] == \"re\":  # Rectangle (thin vertical)\n",
        "                        if len(item) >= 2:\n",
        "                            rect = item[1]\n",
        "                            if rect.width <= 5 and rect.height > page.rect.height * 0.2:\n",
        "                                vertical_lines.append(rect.x0 + rect.width / 2)\n",
        "\n",
        "                    elif item[0] == \"c\":  # Curve (might be decorative line)\n",
        "                        if len(item) >= 4:\n",
        "                            p1, p2, p3, p4 = item[1], item[2], item[3], item[4]\n",
        "                            # Check if curve is essentially vertical\n",
        "                            x_variance = max(p1.x, p2.x, p3.x, p4.x) - min(p1.x, p2.x, p3.x, p4.x)\n",
        "                            if x_variance < 5:\n",
        "                                avg_x = (p1.x + p2.x + p3.x + p4.x) / 4\n",
        "                                vertical_lines.append(avg_x)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Path detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _detect_lines_from_vectors(self, page) -> List[float]:\n",
        "        \"\"\"Method 2: Detect lines from SVG vector graphics\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            svg_text = page.get_svg_image()\n",
        "\n",
        "            # Enhanced SVG pattern matching\n",
        "            patterns = [\n",
        "                r'<line[^>]*x1=\"([^\"]*)\"[^>]*y1=\"([^\"]*)\"[^>]*x2=\"([^\"]*)\"[^>]*y2=\"([^\"]*)\"[^>]*/?>',\n",
        "                r'<rect[^>]*x=\"([^\"]*)\"[^>]*y=\"([^\"]*)\"[^>]*width=\"([^\"]*)\"[^>]*height=\"([^\"]*)\"[^>]*/?>',\n",
        "                r'<path[^>]*d=\"M\\s*([^,\\s]+)[,\\s]+([^,\\s]+)\\s*L\\s*([^,\\s]+)[,\\s]+([^,\\s]+)\"[^>]*/?>',\n",
        "            ]\n",
        "\n",
        "            for pattern in patterns:\n",
        "                matches = re.findall(pattern, svg_text)\n",
        "\n",
        "                for match in matches:\n",
        "                    try:\n",
        "                        if len(match) == 4:\n",
        "                            if 'line' in pattern or 'path' in pattern:\n",
        "                                x1, y1, x2, y2 = map(float, match)\n",
        "                                if abs(x1 - x2) < 3:  # Vertical line\n",
        "                                    line_length = abs(y2 - y1)\n",
        "                                    if line_length > page.rect.height * 0.2:\n",
        "                                        vertical_lines.append(x1)\n",
        "\n",
        "                            elif 'rect' in pattern:\n",
        "                                x, y, width, height = map(float, match)\n",
        "                                if width <= 5 and height > page.rect.height * 0.2:\n",
        "                                    vertical_lines.append(x + width / 2)\n",
        "\n",
        "                    except (ValueError, IndexError):\n",
        "                        continue\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Vector detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _detect_lines_from_text(self, page) -> List[float]:\n",
        "        \"\"\"Method 3: Detect lines from text characters\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            text_dict = page.get_text(\"dict\")\n",
        "\n",
        "            # Extended line characters\n",
        "            line_chars = ['|', '┃', '┋', '┇', '┆', '│', '║', 'ǀ', '⏐', 'ǁ', '︱', '丨', '｜']\n",
        "\n",
        "            # Collect all text spans with line characters\n",
        "            line_positions = {}\n",
        "\n",
        "            for block in text_dict.get(\"blocks\", []):\n",
        "                if \"lines\" in block:\n",
        "                    for line in block[\"lines\"]:\n",
        "                        for span in line.get(\"spans\", []):\n",
        "                            text = span.get(\"text\", \"\")\n",
        "                            bbox = span.get(\"bbox\", [0, 0, 0, 0])\n",
        "\n",
        "                            for char in line_chars:\n",
        "                                if char in text:\n",
        "                                    char_x = round((bbox[0] + bbox[2]) / 2)\n",
        "\n",
        "                                    if char_x not in line_positions:\n",
        "                                        line_positions[char_x] = 0\n",
        "                                    line_positions[char_x] += text.count(char)\n",
        "\n",
        "            # Filter positions with enough line characters\n",
        "            for x_pos, count in line_positions.items():\n",
        "                if count >= 3:  # At least 3 line characters\n",
        "                    vertical_lines.append(float(x_pos))\n",
        "\n",
        "            # Also detect repeated patterns that might indicate borders\n",
        "            full_text = page.get_text()\n",
        "\n",
        "            # Look for repeated sequences that might be borders\n",
        "            border_patterns = ['|', '-|', '|-', '||', '│', '──']\n",
        "\n",
        "            for pattern in border_patterns:\n",
        "                if full_text.count(pattern) > 5:  # Pattern appears multiple times\n",
        "                    # This suggests there might be a structured layout\n",
        "                    # Add common positions for such patterns\n",
        "                    page_width = page.rect.width\n",
        "                    common_ratios = [0.25, 0.33, 0.4, 0.5, 0.6, 0.67, 0.75]\n",
        "\n",
        "                    for ratio in common_ratios:\n",
        "                        if any(abs(line/page_width - ratio) < 0.05 for line in vertical_lines):\n",
        "                            # Only add if we already detected something near this ratio\n",
        "                            vertical_lines.append(page_width * ratio)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Text line detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _detect_lines_from_images(self, page) -> List[float]:\n",
        "        \"\"\"Method 4: Detect lines from embedded images\"\"\"\n",
        "        vertical_lines = []\n",
        "\n",
        "        try:\n",
        "            # Get images on the page\n",
        "            image_list = page.get_images()\n",
        "\n",
        "            for img in image_list:\n",
        "                try:\n",
        "                    bbox = page.get_image_bbox(img)\n",
        "                    if bbox:\n",
        "                        # Check if image is thin and vertical (might be a line)\n",
        "                        if bbox.width <= 10 and bbox.height > page.rect.height * 0.2:\n",
        "                            vertical_lines.append(bbox.x0 + bbox.width / 2)\n",
        "\n",
        "                        # Check for images that might contain line graphics\n",
        "                        if bbox.width > 20 and bbox.height > page.rect.height * 0.5:\n",
        "                            # This might be a large image with embedded lines\n",
        "                            # Add common split positions within the image\n",
        "                            img_center = bbox.x0 + bbox.width / 2\n",
        "\n",
        "                            # Check if image spans a significant portion of the page\n",
        "                            if bbox.width > page.rect.width * 0.3:\n",
        "                                vertical_lines.append(img_center)\n",
        "\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.debug_mode:\n",
        "                print(f\"   ⚠️ Image line detection error: {e}\")\n",
        "\n",
        "        return vertical_lines\n",
        "\n",
        "    def _filter_and_clean_lines(self, lines: List[float], page_width: float) -> List[float]:\n",
        "        \"\"\"Filter and clean detected lines\"\"\"\n",
        "        if not lines:\n",
        "            return []\n",
        "\n",
        "        # Remove duplicates with tolerance\n",
        "        cleaned_lines = []\n",
        "        lines.sort()\n",
        "\n",
        "        for line in lines:\n",
        "            # Check if this line is valid (within page bounds and reasonable position)\n",
        "            if 0.1 * page_width <= line <= 0.9 * page_width:\n",
        "                # Check if it's too close to an existing line\n",
        "                if not any(abs(line - existing) < page_width * 0.02 for existing in cleaned_lines):\n",
        "                    cleaned_lines.append(line)\n",
        "\n",
        "        return cleaned_lines\n",
        "\n",
        "    def _analyze_all_detected_lines(self, all_lines: List[float], page_analyses: List[Dict]) -> Dict:\n",
        "        \"\"\"Analyze all detected lines to find optimal split\"\"\"\n",
        "\n",
        "        if not all_lines or not page_analyses:\n",
        "            return self._get_fallback_analysis()\n",
        "\n",
        "        page_width = page_analyses[0]['page_width']\n",
        "\n",
        "        # Convert to ratios and filter\n",
        "        line_ratios = []\n",
        "        for line in all_lines:\n",
        "            ratio = line / page_width\n",
        "            if 0.15 <= ratio <= 0.85:  # Reasonable split range\n",
        "                line_ratios.append(ratio)\n",
        "\n",
        "        if not line_ratios:\n",
        "            return self._get_fallback_analysis()\n",
        "\n",
        "        # Advanced clustering with multiple methods\n",
        "        clusters = self._perform_advanced_clustering(line_ratios)\n",
        "\n",
        "        if not clusters:\n",
        "            return self._get_fallback_analysis()\n",
        "\n",
        "        # Select best cluster\n",
        "        best_cluster = self._select_best_cluster(clusters, page_analyses)\n",
        "\n",
        "        # Calculate final metrics\n",
        "        optimal_split = sum(best_cluster['ratios']) / len(best_cluster['ratios'])\n",
        "        confidence = self._calculate_confidence(best_cluster, clusters, page_analyses)\n",
        "        consistency = self._calculate_consistency(best_cluster)\n",
        "\n",
        "        return {\n",
        "            'optimal_split': optimal_split,\n",
        "            'confidence': confidence,\n",
        "            'line_consistency': consistency,\n",
        "            'detected_lines': all_lines,\n",
        "            'line_ratios': line_ratios,\n",
        "            'clusters': clusters,\n",
        "            'best_cluster': best_cluster,\n",
        "            'method': 'advanced_line_detection',\n",
        "            'pages_analyzed': len(page_analyses),\n",
        "            'detection_summary': {\n",
        "                'total_lines_found': len(all_lines),\n",
        "                'valid_ratios': len(line_ratios),\n",
        "                'clusters_found': len(clusters),\n",
        "                'best_cluster_size': len(best_cluster['ratios'])\n",
        "            },\n",
        "            'page_details': page_analyses\n",
        "        }\n",
        "\n",
        "    def _perform_advanced_clustering(self, ratios: List[float]) -> List[Dict]:\n",
        "        \"\"\"Perform advanced clustering of line positions\"\"\"\n",
        "        if not ratios:\n",
        "            return []\n",
        "\n",
        "        ratios_sorted = sorted(ratios)\n",
        "        clusters = []\n",
        "\n",
        "        # Dynamic tolerance based on data distribution\n",
        "        tolerance = max(0.02, (max(ratios) - min(ratios)) / 10)\n",
        "\n",
        "        for ratio in ratios_sorted:\n",
        "            added = False\n",
        "\n",
        "            for cluster in clusters:\n",
        "                cluster_center = sum(cluster['ratios']) / len(cluster['ratios'])\n",
        "                if abs(ratio - cluster_center) <= tolerance:\n",
        "                    cluster['ratios'].append(ratio)\n",
        "                    added = True\n",
        "                    break\n",
        "\n",
        "            if not added:\n",
        "                clusters.append({\n",
        "                    'ratios': [ratio],\n",
        "                    'center': ratio,\n",
        "                    'weight': 1\n",
        "                })\n",
        "\n",
        "        # Update cluster centers and weights\n",
        "        for cluster in clusters:\n",
        "            cluster['center'] = sum(cluster['ratios']) / len(cluster['ratios'])\n",
        "            cluster['weight'] = len(cluster['ratios'])\n",
        "            cluster['spread'] = max(cluster['ratios']) - min(cluster['ratios']) if len(cluster['ratios']) > 1 else 0\n",
        "\n",
        "        return clusters\n",
        "\n",
        "    def _select_best_cluster(self, clusters: List[Dict], page_analyses: List[Dict]) -> Dict:\n",
        "        \"\"\"Select the best cluster based on multiple criteria\"\"\"\n",
        "\n",
        "        def score_cluster(cluster):\n",
        "            # Weight (frequency)\n",
        "            weight_score = cluster['weight'] / len(page_analyses)\n",
        "\n",
        "            # Consistency (low spread)\n",
        "            spread_score = 1 - min(1, cluster['spread'] / 0.1)\n",
        "\n",
        "            # Position preference (avoid extreme edges)\n",
        "            center = cluster['center']\n",
        "            position_score = 1 - abs(center - 0.5) * 2  # Prefer center positions\n",
        "\n",
        "            # Combined score\n",
        "            return (weight_score * 0.5 + spread_score * 0.3 + position_score * 0.2)\n",
        "\n",
        "        return max(clusters, key=score_cluster)\n",
        "\n",
        "    def _calculate_confidence(self, best_cluster: Dict, all_clusters: List[Dict], page_analyses: List[Dict]) -> float:\n",
        "        \"\"\"Calculate confidence in the detection\"\"\"\n",
        "\n",
        "        # Frequency confidence\n",
        "        frequency_conf = min(1.0, best_cluster['weight'] / len(page_analyses))\n",
        "\n",
        "        # Consistency confidence\n",
        "        consistency_conf = 1 - min(1, best_cluster['spread'] / 0.05)\n",
        "\n",
        "        # Method diversity confidence\n",
        "        total_methods = sum(\n",
        "            sum(page['methods_count'].values())\n",
        "            for page in page_analyses\n",
        "        )\n",
        "        method_conf = min(1.0, total_methods / (len(page_analyses) * 2))\n",
        "\n",
        "        # Dominance confidence (how much better is this cluster than others)\n",
        "        if len(all_clusters) > 1:\n",
        "            other_weights = [c['weight'] for c in all_clusters if c != best_cluster]\n",
        "            dominance_conf = best_cluster['weight'] / (max(other_weights) + 1) if other_weights else 1.0\n",
        "            dominance_conf = min(1.0, dominance_conf)\n",
        "        else:\n",
        "            dominance_conf = 1.0\n",
        "\n",
        "        # Combined confidence\n",
        "        confidence = (frequency_conf * 0.3 + consistency_conf * 0.3 +\n",
        "                     method_conf * 0.2 + dominance_conf * 0.2)\n",
        "\n",
        "        return confidence\n",
        "\n",
        "    def _calculate_consistency(self, cluster: Dict) -> float:\n",
        "        \"\"\"Calculate consistency of the cluster\"\"\"\n",
        "        if len(cluster['ratios']) <= 1:\n",
        "            return 1.0\n",
        "\n",
        "        return 1 - min(1, cluster['spread'] / 0.1)\n",
        "\n",
        "    def _get_fallback_analysis(self) -> Dict:\n",
        "        \"\"\"Fallback analysis when line detection fails\"\"\"\n",
        "        return {\n",
        "            'optimal_split': 0.5,\n",
        "            'confidence': 0.1,\n",
        "            'line_consistency': 0.0,\n",
        "            'detected_lines': [],\n",
        "            'method': 'fallback',\n",
        "            'detection_summary': {\n",
        "                'total_lines_found': 0,\n",
        "                'valid_ratios': 0,\n",
        "                'clusters_found': 0,\n",
        "                'best_cluster_size': 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # =============================================================================\n",
        "    # 🧠 CONTENT ANALYSIS SYSTEM\n",
        "    # =============================================================================\n",
        "\n",
        "    def analyze_content_layout(self, pdf_path: str, sample_pages: int = 5) -> Dict:\n",
        "        \"\"\"Comprehensive content analysis\"\"\"\n",
        "\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        try:\n",
        "            sample_pages = min(sample_pages, len(doc))\n",
        "            print(f\"🧠 Analyzing content layout from {sample_pages} pages...\")\n",
        "\n",
        "            content_analysis = {\n",
        "                'text_density_map': [],\n",
        "                'layout_patterns': [],\n",
        "                'font_analysis': [],\n",
        "                'image_positions': [],\n",
        "                'whitespace_analysis': []\n",
        "            }\n",
        "\n",
        "            for page_num in range(sample_pages):\n",
        "                page = doc[page_num]\n",
        "\n",
        "                # Analyze text density\n",
        "                density_analysis = self._analyze_text_density(page)\n",
        "                content_analysis['text_density_map'].append(density_analysis)\n",
        "\n",
        "                # Analyze layout patterns\n",
        "                layout_analysis = self._analyze_layout_patterns(page)\n",
        "                content_analysis['layout_patterns'].append(layout_analysis)\n",
        "\n",
        "                # Analyze fonts and formatting\n",
        "                font_analysis = self._analyze_fonts_and_formatting(page)\n",
        "                content_analysis['font_analysis'].append(font_analysis)\n",
        "\n",
        "                # Analyze images and graphics\n",
        "                image_analysis = self._analyze_images_and_graphics(page)\n",
        "                content_analysis['image_positions'].append(image_analysis)\n",
        "\n",
        "                # Analyze whitespace\n",
        "                whitespace_analysis = self._analyze_whitespace_distribution(page)\n",
        "                content_analysis['whitespace_analysis'].append(whitespace_analysis)\n",
        "\n",
        "            # Combine all analyses\n",
        "            final_content_analysis = self._combine_content_analyses(content_analysis)\n",
        "\n",
        "            return final_content_analysis\n",
        "\n",
        "        finally:\n",
        "            doc.close()\n",
        "\n",
        "    def _analyze_text_density(self, page) -> Dict:\n",
        "        \"\"\"Analyze text density across the page\"\"\"\n",
        "        rect = page.rect\n",
        "\n",
        "        # Create density grid\n",
        "        grid_cols, grid_rows = 20, 20\n",
        "        density_grid = [[0 for _ in range(grid_cols)] for _ in range(grid_rows)]\n",
        "\n",
        "        # Get text blocks\n",
        "        text_dict = page.get_text(\"dict\")\n",
        "\n",
        "        for block in text_dict.get(\"blocks\", []):\n",
        "            if \"lines\" in block:\n",
        "                bbox = block[\"bbox\"]\n",
        "                text_length = 0\n",
        "\n",
        "                for line in block[\"lines\"]:\n",
        "                    for span in line.get(\"spans\", []):\n",
        "                        text_length += len(span.get(\"text\", \"\").strip())\n",
        "\n",
        "                if text_length > 0:\n",
        "                    # Map to grid\n",
        "                    col = min(int((bbox[0] + bbox[2]) / 2 / rect.width * grid_cols), grid_cols - 1)\n",
        "                    row = min(int((bbox[1] + bbox[3]) / 2 / rect.height * grid_rows), grid_rows - 1)\n",
        "\n",
        "                    density_grid[row][col] += text_length\n",
        "\n",
        "        # Analyze vertical distribution\n",
        "        vertical_density = [sum(density_grid[row][col] for row in range(grid_rows)) for col in range(grid_cols)]\n",
        "\n",
        "        # Find optimal vertical split\n",
        "        min_density_col = 0\n",
        "        min_density = float('inf')\n",
        "\n",
        "        for col in range(int(grid_cols * 0.2), int(grid_cols * 0.8)):\n",
        "            if vertical_density[col] < min_density:\n",
        "                min_density = vertical_density[col]\n",
        "                min_density_col = col\n",
        "\n",
        "        optimal_split = (min_density_col + 0.5) / grid_cols\n",
        "\n",
        "        return {\n",
        "            'density_grid': density_grid,\n",
        "            'vertical_density': vertical_density,\n",
        "            'optimal_split': optimal_split,\n",
        "            'total_text': sum(vertical_density)\n",
        "        }\n",
        "\n",
        "    def _analyze_layout_patterns(self, page) -> Dict:\n",
        "        \"\"\"Analyze layout patterns and structure\"\"\"\n",
        "        text_dict = page.get_text(\"dict\")\n",
        "\n",
        "        patterns = {\n",
        "            'columns': 0,\n",
        "            'alignment_patterns': {'left': 0, 'center': 0, 'right': 0},\n",
        "            'spacing_patterns': [],\n",
        "            'block_sizes': []\n",
        "        }\n",
        "\n",
        "        block_positions = []\n",
        "\n",
        "        for block in text_dict.get(\"blocks\", []):\n",
        "            if \"lines\" in block:\n",
        "                bbox = block[\"bbox\"]\n",
        "                block_width = bbox[2] - bbox[0]\n",
        "                block_height = bbox[3] - bbox[1]\n",
        "\n",
        "                patterns['block_sizes'].append({\n",
        "                    'width': block_width,\n",
        "                    'height': block_height,\n",
        "                    'x': bbox[0],\n",
        "                    'y': bbox[1]\n",
        "                })\n",
        "\n",
        "                block_positions.append(bbox[0])  # Left edge\n",
        "\n",
        "                # Analyze alignment\n",
        "                page_width = page.rect.width\n",
        "                if bbox[0] < page_width * 0.1:\n",
        "                    patterns['alignment_patterns']['left'] += 1\n",
        "                elif bbox[2] > page_width * 0.9:\n",
        "                    patterns['alignment_patterns']['right'] += 1\n",
        "                else:\n",
        "                    patterns['alignment_patterns']['center'] += 1\n",
        "\n",
        "        # Detect column structure\n",
        "        if block_positions:\n",
        "            block_positions.sort()\n",
        "            gaps = []\n",
        "\n",
        "            for i in range(1, len(block_positions)):\n",
        "                gap = block_positions[i] - block_positions[i-1]\n",
        "                if gap > 20:  # Significant gap\n",
        "                    gaps.append(gap)\n",
        "\n",
        "            patterns['spacing_patterns'] = gaps\n",
        "            patterns['columns'] = len(set(round(pos / 50) * 50 for pos in block_positions))\n",
        "\n",
        "        return patterns\n",
        "\n",
        "    def _analyze_fonts_and_formatting(self, page) -> Dict:\n",
        "        \"\"\"Analyze fonts and text formatting\"\"\"\n",
        "        text_dict = page.get_text(\"dict\")\n",
        "\n",
        "        font_analysis = {\n",
        "            'font_sizes': {},\n",
        "            'font_families': {},\n",
        "            'text_styles': {'bold': 0, 'italic': 0, 'normal': 0},\n",
        "            'color_distribution': {}\n",
        "        }\n",
        "\n",
        "        for block in text_dict.get(\"blocks\", []):\n",
        "            if \"lines\" in block:\n",
        "                for line in block[\"lines\"]:\n",
        "                    for span in line.get(\"spans\", []):\n",
        "                        # Font size\n",
        "                        size = span.get(\"size\", 12)\n",
        "                        size_key = f\"{size:.1f}\"\n",
        "                        font_analysis['font_sizes'][size_key] = font_analysis['font_sizes'].get(size_key, 0) + 1\n",
        "\n",
        "                        # Font family\n",
        "                        font = span.get(\"font\", \"unknown\")\n",
        "                        font_analysis['font_families'][font] = font_analysis['font_families'].get(font, 0) + 1\n",
        "\n",
        "                        # Text style\n",
        "                        flags = span.get(\"flags\", 0)\n",
        "                        if flags & 2**4:  # Bold\n",
        "                            font_analysis['text_styles']['bold'] += 1\n",
        "                        elif flags & 2**1:  # Italic\n",
        "                            font_analysis['text_styles']['italic'] += 1\n",
        "                        else:\n",
        "                            font_analysis['text_styles']['normal'] += 1\n",
        "\n",
        "        return font_analysis\n",
        "\n",
        "    def _analyze_images_and_graphics(self, page) -> Dict:\n",
        "        \"\"\"Analyze images and graphics distribution\"\"\"\n",
        "        images = page.get_images()\n",
        "        drawings = page.get_drawings()\n",
        "\n",
        "        image_analysis = {\n",
        "            'image_count': len(images),\n",
        "            'drawing_count': len(drawings),\n",
        "            'image_positions': [],\n",
        "            'drawing_positions': []\n",
        "        }\n",
        "\n",
        "        # Analyze image positions\n",
        "        for img in images:\n",
        "            try:\n",
        "                bbox = page.get_image_bbox(img)\n",
        "                if bbox:\n",
        "                    image_analysis['image_positions'].append({\n",
        "                        'x': bbox.x0,\n",
        "                        'y': bbox.y0,\n",
        "                        'width': bbox.width,\n",
        "                        'height': bbox.height,\n",
        "                        'center_x': bbox.x0 + bbox.width / 2\n",
        "                    })\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Analyze drawing positions\n",
        "        for drawing in drawings:\n",
        "            try:\n",
        "                rect = drawing.get(\"rect\")\n",
        "                if rect:\n",
        "                    image_analysis['drawing_positions'].append({\n",
        "                        'x': rect.x0,\n",
        "                        'y': rect.y0,\n",
        "                        'width': rect.width,\n",
        "                        'height': rect.height,\n",
        "                        'center_x': rect.x0 + rect.width / 2\n",
        "                    })\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return image_analysis\n",
        "\n",
        "    def _analyze_whitespace_distribution(self, page) -> Dict:\n",
        "        \"\"\"Analyze whitespace distribution\"\"\"\n",
        "        text_dict = page.get_text(\"dict\")\n",
        "        page_width = page.rect.width\n",
        "        page_height = page.rect.height\n",
        "\n",
        "        # Create occupancy map\n",
        "        occupied_areas = []\n",
        "\n",
        "        for block in text_dict.get(\"blocks\", []):\n",
        "            if \"lines\" in block:\n",
        "                bbox = block[\"bbox\"]\n",
        "                occupied_areas.append(bbox)\n",
        "\n",
        "        # Add images\n",
        "        images = page.get_images()\n",
        "        for img in images:\n",
        "            try:\n",
        "                bbox = page.get_image_bbox(img)\n",
        "                if bbox:\n",
        "                    occupied_areas.append([bbox.x0, bbox.y0, bbox.x1, bbox.y1])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Find largest vertical gaps\n",
        "        vertical_gaps = []\n",
        "\n",
        "        if occupied_areas:\n",
        "            # Sort by x-coordinate\n",
        "            x_positions = []\n",
        "            for area in occupied_areas:\n",
        "                x_positions.extend([area[0], area[2]])\n",
        "\n",
        "            x_positions.sort()\n",
        "\n",
        "            for i in range(1, len(x_positions)):\n",
        "                gap = x_positions[i] - x_positions[i-1]\n",
        "                if gap > page_width * 0.02:  # Significant gap\n",
        "                    gap_center = (x_positions[i] + x_positions[i-1]) / 2\n",
        "                    vertical_gaps.append({\n",
        "                        'position': gap_center,\n",
        "                        'size': gap,\n",
        "                        'ratio': gap_center / page_width\n",
        "                    })\n",
        "\n",
        "        return {\n",
        "            'vertical_gaps': vertical_gaps,\n",
        "            'largest_gap': max(vertical_gaps, key=lambda g: g['size']) if vertical_gaps else None\n",
        "        }\n",
        "\n",
        "    def _combine_content_analyses(self, content_analysis: Dict) -> Dict:\n",
        "        \"\"\"Combine all content analyses\"\"\"\n",
        "\n",
        "        # Average the results across pages\n",
        "        combined = {\n",
        "            'recommended_split': 0.5,\n",
        "            'confidence': 0.1,\n",
        "            'method': 'content_analysis',\n",
        "            'evidence': []\n",
        "        }\n",
        "\n",
        "        split_suggestions = []\n",
        "        confidences = []\n",
        "\n",
        "        # From text density\n",
        "        for density in content_analysis['text_density_map']:\n",
        "            split_suggestions.append(density['optimal_split'])\n",
        "            confidences.append(0.3)  # Base confidence for density analysis\n",
        "\n",
        "        # From whitespace analysis\n",
        "        for whitespace in content_analysis['whitespace_analysis']:\n",
        "            if whitespace['largest_gap']:\n",
        "                gap = whitespace['largest_gap']\n",
        "                if 0.2 <= gap['ratio'] <= 0.8:  # Reasonable range\n",
        "                    split_suggestions.append(gap['ratio'])\n",
        "                    confidences.append(0.7)  # Higher confidence for clear gaps\n",
        "\n",
        "        # Calculate weighted average\n",
        "        if split_suggestions and confidences:\n",
        "            total_weight = sum(confidences)\n",
        "            weighted_split = sum(s * c for s, c in zip(split_suggestions, confidences)) / total_weight\n",
        "            avg_confidence = sum(confidences) / len(confidences)\n",
        "\n",
        "            combined['recommended_split'] = weighted_split\n",
        "            combined['confidence'] = avg_confidence\n",
        "\n",
        "        return combined\n",
        "\n",
        "    # =============================================================================\n",
        "    # 🎯 MULTI-METHOD DETECTION SYSTEM\n",
        "    # =============================================================================\n",
        "\n",
        "    def detect_optimal_split_multi_method(self, pdf_path: str) -> Dict:\n",
        "        \"\"\"Use multiple methods to detect optimal split ratio\"\"\"\n",
        "\n",
        "        print(\"🎯 Running comprehensive multi-method analysis...\")\n",
        "\n",
        "        # Method 1: Line Detection\n",
        "        print(\"📏 Method 1: Vertical line detection...\")\n",
        "        line_analysis = self.detect_vertical_lines(pdf_path)\n",
        "\n",
        "        # Method 2: Content Analysis\n",
        "        print(\"🧠 Method 2: Content layout analysis...\")\n",
        "        content_analysis = self.analyze_content_layout(pdf_path)\n",
        "\n",
        "        # Method 3: Visual Pattern Recognition\n",
        "        print(\"👁️ Method 3: Visual pattern recognition...\")\n",
        "        visual_analysis = self._analyze_visual_patterns(pdf_path)\n",
        "\n",
        "        # Method 4: Document Structure Analysis\n",
        "        print(\"📋 Method 4: Document structure analysis...\")\n",
        "        structure_analysis = self._analyze_document_structure(pdf_path)\n",
        "\n",
        "        # Combine all methods\n",
        "        print(\"🔄 Combining all analysis methods...\")\n",
        "        final_analysis = self._combine_all_methods(\n",
        "            line_analysis, content_analysis, visual_analysis, structure_analysis\n",
        "        )\n",
        "\n",
        "        return final_analysis\n",
        "\n",
        "    def _analyze_visual_patterns(self, pdf_path: str) -> Dict:\n",
        "        \"\"\"Analyze visual patterns in the document\"\"\"\n",
        "\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        try:\n",
        "            # Sample pages for visual analysis\n",
        "            sample_pages = min(3, len(doc))\n",
        "            visual_patterns = []\n",
        "\n",
        "            for page_num in range(sample_pages):\n",
        "                page = doc[page_num]\n",
        "\n",
        "                # Convert page to image for visual analysis\n",
        "                mat = fitz.Matrix(1.0, 1.0)  # No scaling\n",
        "                pix = page.get_pixmap(matrix=mat)\n",
        "\n",
        "                # Analyze pixel patterns (simplified)\n",
        "                page_analysis = {\n",
        "                    'page_width': page.rect.width,\n",
        "                    'page_height': page.rect.height,\n",
        "                    'visual_split_suggestions': []\n",
        "                }\n",
        "\n",
        "                # Look for clear vertical divisions in content\n",
        "                # This is a simplified approach - in practice, you might use image processing\n",
        "                text_blocks = page.get_text(\"dict\").get(\"blocks\", [])\n",
        "\n",
        "                if text_blocks:\n",
        "                    x_positions = []\n",
        "                    for block in text_blocks:\n",
        "                        if \"bbox\" in block:\n",
        "                            bbox = block[\"bbox\"]\n",
        "                            x_positions.extend([bbox[0], bbox[2]])\n",
        "\n",
        "                    if x_positions:\n",
        "                        x_positions.sort()\n",
        "\n",
        "                        # Find gaps\n",
        "                        for i in range(1, len(x_positions)):\n",
        "                            gap = x_positions[i] - x_positions[i-1]\n",
        "                            if gap > page.rect.width * 0.05:  # Significant gap\n",
        "                                gap_center = (x_positions[i] + x_positions[i-1]) / 2\n",
        "                                gap_ratio = gap_center / page.rect.width\n",
        "\n",
        "                                if 0.2 <= gap_ratio <= 0.8:\n",
        "                                    page_analysis['visual_split_suggestions'].append(gap_ratio)\n",
        "\n",
        "                visual_patterns.append(page_analysis)\n",
        "\n",
        "            # Combine visual analysis\n",
        "            all_suggestions = []\n",
        "            for pattern in visual_patterns:\n",
        "                all_suggestions.extend(pattern['visual_split_suggestions'])\n",
        "\n",
        "            if all_suggestions:\n",
        "                optimal_split = sum(all_suggestions) / len(all_suggestions)\n",
        "                confidence = min(1.0, len(all_suggestions) / 3)  # More suggestions = higher confidence\n",
        "            else:\n",
        "                optimal_split = 0.5\n",
        "                confidence = 0.1\n",
        "\n",
        "            return {\n",
        "                'optimal_split': optimal_split,\n",
        "                'confidence': confidence,\n",
        "                'method': 'visual_pattern_analysis',\n",
        "                'suggestions': all_suggestions\n",
        "            }\n",
        "\n",
        "        finally:\n",
        "            doc.close()\n",
        "\n",
        "    def _analyze_document_structure(self, pdf_path: str) -> Dict:\n",
        "        \"\"\"Analyze document structure and metadata\"\"\"\n",
        "\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        try:\n",
        "            structure_analysis = {\n",
        "                'page_count': len(doc),\n",
        "                'page_dimensions': [],\n",
        "                'text_statistics': {},\n",
        "                'structure_hints': []\n",
        "            }\n",
        "\n",
        "            # Analyze first few pages for structure\n",
        "            sample_pages = min(5, len(doc))\n",
        "            total_text = \"\"\n",
        "\n",
        "            for page_num in range(sample_pages):\n",
        "                page = doc[page_num]\n",
        "\n",
        "                structure_analysis['page_dimensions'].append({\n",
        "                    'width': page.rect.width,\n",
        "                    'height': page.rect.height,\n",
        "                    'ratio': page.rect.width / page.rect.height\n",
        "                })\n",
        "\n",
        "                page_text = page.get_text()\n",
        "                total_text += page_text\n",
        "\n",
        "            # Analyze text for structural hints\n",
        "            structure_hints = []\n",
        "\n",
        "            # Check for exam/question patterns\n",
        "            exam_keywords = ['question', 'answer', 'select', 'choose', 'option', 'practice', 'test', 'exam']\n",
        "            for keyword in exam_keywords:\n",
        "                if keyword.lower() in total_text.lower():\n",
        "                    structure_hints.append(f\"exam_paper_{keyword}\")\n",
        "\n",
        "            # Check for telegram/social media references\n",
        "            social_keywords = ['telegram', 'join', 'click here', 'open', 'subscribe']\n",
        "            for keyword in social_keywords:\n",
        "                if keyword.lower() in total_text.lower():\n",
        "                    structure_hints.append(f\"social_media_{keyword}\")\n",
        "\n",
        "            # Check for two-column indicators\n",
        "            column_indicators = ['column', 'left', 'right', 'side']\n",
        "            for indicator in column_indicators:\n",
        "                if indicator.lower() in total_text.lower():\n",
        "                    structure_hints.append(f\"column_layout_{indicator}\")\n",
        "\n",
        "            structure_analysis['structure_hints'] = structure_hints\n",
        "\n",
        "            # Determine likely split based on structure\n",
        "            if any('exam_paper' in hint for hint in structure_hints):\n",
        "                if any('social_media' in hint for hint in structure_hints):\n",
        "                    # Exam paper with social media reference - likely split needed\n",
        "                    suggested_split = 0.6  # Questions on left (60%), social media on right (40%)\n",
        "                    confidence = 0.8\n",
        "                else:\n",
        "                    # Pure exam paper - might not need split or different ratio\n",
        "                    suggested_split = 0.5\n",
        "                    confidence = 0.4\n",
        "            else:\n",
        "                # Unknown structure\n",
        "                suggested_split = 0.5\n",
        "                confidence = 0.2\n",
        "\n",
        "            return {\n",
        "                'optimal_split': suggested_split,\n",
        "                'confidence': confidence,\n",
        "                'method': 'document_structure_analysis',\n",
        "                'structure_hints': structure_hints,\n",
        "                'analysis': structure_analysis\n",
        "            }\n",
        "\n",
        "        finally:\n",
        "            doc.close()\n",
        "\n",
        "    def _combine_all_methods(self, line_analysis: Dict, content_analysis: Dict,\n",
        "                           visual_analysis: Dict, structure_analysis: Dict) -> Dict:\n",
        "        \"\"\"Combine results from all analysis methods\"\"\"\n",
        "\n",
        "        methods = [\n",
        "            ('line_detection', line_analysis),\n",
        "            ('content_analysis', content_analysis),\n",
        "            ('visual_analysis', visual_analysis),\n",
        "            ('structure_analysis', structure_analysis)\n",
        "        ]\n",
        "\n",
        "        # Weight methods by their confidence\n",
        "        weighted_splits = []\n",
        "        weighted_confidences = []\n",
        "        method_details = {}\n",
        "\n",
        "        for method_name, analysis in methods:\n",
        "            split = analysis.get('optimal_split', 0.5)\n",
        "            confidence = analysis.get('confidence', 0.1)\n",
        "\n",
        "            weighted_splits.append(split * confidence)\n",
        "            weighted_confidences.append(confidence)\n",
        "\n",
        "            method_details[method_name] = {\n",
        "                'split': split,\n",
        "                'confidence': confidence,\n",
        "                'details': analysis\n",
        "            }\n",
        "\n",
        "        # Calculate final weighted average\n",
        "        total_weight = sum(weighted_confidences)\n",
        "\n",
        "        if total_weight > 0:\n",
        "            final_split = sum(weighted_splits) / total_weight\n",
        "            final_confidence = sum(weighted_confidences) / len(weighted_confidences)\n",
        "        else:\n",
        "            final_split = 0.5\n",
        "            final_confidence = 0.1\n",
        "\n",
        "        # Adjust confidence based on method agreement\n",
        "        splits_only = [analysis.get('optimal_split', 0.5) for _, analysis in methods]\n",
        "        split_variance = np.var(splits_only) if len(splits_only) > 1 else 0\n",
        "        agreement_factor = max(0.1, 1 - split_variance * 5)  # Higher variance = lower agreement\n",
        "\n",
        "        final_confidence *= agreement_factor\n",
        "\n",
        "        return {\n",
        "            'optimal_split': final_split,\n",
        "            'confidence': final_confidence,\n",
        "            'agreement_factor': agreement_factor,\n",
        "            'method': 'multi_method_combined',\n",
        "            'individual_methods': method_details,\n",
        "            'summary': {\n",
        "                'line_detection_confidence': line_analysis.get('confidence', 0),\n",
        "                'content_analysis_confidence': content_analysis.get('confidence', 0),\n",
        "                'visual_analysis_confidence': visual_analysis.get('confidence', 0),\n",
        "                'structure_analysis_confidence': structure_analysis.get('confidence', 0),\n",
        "                'methods_agreement': agreement_factor,\n",
        "                'recommended_split': final_split\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # =============================================================================\n",
        "    # ✂️ PDF SPLITTING ENGINE\n",
        "    # =============================================================================\n",
        "\n",
        "    def split_pdf_with_analysis(self, input_path: str, output_path: str,\n",
        "                               method: str = \"multi_method\") -> bool:\n",
        "        \"\"\"Split PDF using comprehensive analysis\"\"\"\n",
        "\n",
        "        input_doc = None\n",
        "        output_doc = None\n",
        "\n",
        "        try:\n",
        "            # Step 1: Comprehensive Analysis\n",
        "            print(\"🔍 Step 1: Comprehensive PDF Analysis\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            if method == \"multi_method\":\n",
        "                analysis = self.detect_optimal_split_multi_method(input_path)\n",
        "            elif method == \"line_detection\":\n",
        "                analysis = self.detect_vertical_lines(input_path)\n",
        "            elif method == \"content_analysis\":\n",
        "                analysis = self.analyze_content_layout(input_path)\n",
        "            else:\n",
        "                # Fallback to multi-method\n",
        "                analysis = self.detect_optimal_split_multi_method(input_path)\n",
        "\n",
        "            optimal_ratio = analysis.get('optimal_split', 0.5)\n",
        "            confidence = analysis.get('confidence', 0.1)\n",
        "\n",
        "            print(f\"\\n📊 Analysis Results:\")\n",
        "            print(f\"   • Detection method: {analysis.get('method', 'unknown')}\")\n",
        "            print(f\"   • Optimal split ratio: {optimal_ratio:.1%}\")\n",
        "            print(f\"   • Detection confidence: {confidence:.1%}\")\n",
        "\n",
        "            if 'summary' in analysis:\n",
        "                summary = analysis['summary']\n",
        "                print(f\"   • Line detection confidence: {summary.get('line_detection_confidence', 0):.1%}\")\n",
        "                print(f\"   • Content analysis confidence: {summary.get('content_analysis_confidence', 0):.1%}\")\n",
        "                print(f\"   • Methods agreement: {summary.get('methods_agreement', 0):.1%}\")\n",
        "\n",
        "            # Validate the detected ratio\n",
        "            if optimal_ratio < 0.15 or optimal_ratio > 0.85:\n",
        "                print(f\"⚠️ Warning: Detected ratio {optimal_ratio:.1%} seems extreme. Using safer ratio.\")\n",
        "                optimal_ratio = max(0.2, min(0.8, optimal_ratio))\n",
        "\n",
        "            if confidence < 0.3:\n",
        "                print(f\"⚠️ Warning: Low confidence ({confidence:.1%}). Results may not be optimal.\")\n",
        "\n",
        "            # Step 2: Apply Split\n",
        "            print(f\"\\n✂️ Step 2: Applying Split at {optimal_ratio:.1%}\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            input_doc = fitz.open(input_path)\n",
        "            output_doc = fitz.open()\n",
        "\n",
        "            page_count = len(input_doc)\n",
        "            success_count = 0\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            with tqdm(total=page_count, desc=\"📄 Processing\", unit=\"page\") as pbar:\n",
        "                for page_num in range(page_count):\n",
        "                    try:\n",
        "                        page = input_doc[page_num]\n",
        "                        rect = page.rect\n",
        "\n",
        "                        # Calculate split position\n",
        "                        split_pos = rect.width * optimal_ratio\n",
        "\n",
        "                        # Create left half\n",
        "                        left_clip = fitz.Rect(0, 0, split_pos, rect.height)\n",
        "                        left_page = output_doc.new_page(width=split_pos, height=rect.height)\n",
        "                        left_page.show_pdf_page(fitz.Rect(0, 0, split_pos, rect.height),\n",
        "                                               input_doc, page_num, clip=left_clip)\n",
        "\n",
        "                        # Create right half\n",
        "                        right_clip = fitz.Rect(split_pos, 0, rect.width, rect.height)\n",
        "                        right_page = output_doc.new_page(width=rect.width - split_pos, height=rect.height)\n",
        "                        right_page.show_pdf_page(fitz.Rect(0, 0, rect.width - split_pos, rect.height),\n",
        "                                                input_doc, page_num, clip=right_clip)\n",
        "\n",
        "                        success_count += 1\n",
        "                        pbar.set_postfix({\n",
        "                            'Split': f\"{optimal_ratio:.1%}\",\n",
        "                            'Success': f\"{success_count}/{page_count}\"\n",
        "                        })\n",
        "                        pbar.update(1)\n",
        "\n",
        "                        # Memory management\n",
        "                        if (page_num + 1) % 10 == 0:\n",
        "                            gc.collect()\n",
        "\n",
        "                    except Exception as page_error:\n",
        "                        print(f\"⚠️ Page {page_num + 1} error: {page_error}\")\n",
        "                        continue\n",
        "\n",
        "            # Step 3: Save Results\n",
        "            print(\"\\n💾 Step 3: Saving Results\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            if len(output_doc) == 0:\n",
        "                print(\"❌ No pages were processed successfully\")\n",
        "                return False\n",
        "\n",
        "            try:\n",
        "                # Save with optimization\n",
        "                output_doc.save(output_path, garbage=4, deflate=True)\n",
        "\n",
        "                # Calculate performance metrics\n",
        "                elapsed_time = time.time() - start_time\n",
        "                output_size = os.path.getsize(output_path) / (1024 * 1024)\n",
        "                created_pages = len(output_doc)\n",
        "\n",
        "                print(f\"✅ Processing Complete!\")\n",
        "                print(f\"\\n📊 Results Summary:\")\n",
        "                print(f\"   • Input file: {os.path.basename(input_path)}\")\n",
        "                print(f\"   • Output file: {os.path.basename(output_path)}\")\n",
        "                print(f\"   • Pages processed: {success_count}/{page_count}\")\n",
        "                print(f\"   • Pages created: {created_pages}\")\n",
        "                print(f\"   • Output size: {output_size:.2f} MB\")\n",
        "                print(f\"   • Processing time: {elapsed_time:.2f} seconds\")\n",
        "                print(f\"   • Speed: {page_count/elapsed_time:.1f} pages/second\")\n",
        "                print(f\"   • Split ratio used: {optimal_ratio:.1%}\")\n",
        "                print(f\"   • Detection confidence: {confidence:.1%}\")\n",
        "                print(f\"   • Success rate: {success_count/page_count:.1%}\")\n",
        "\n",
        "                return True\n",
        "\n",
        "            except Exception as save_error:\n",
        "                print(f\"❌ Save error: {save_error}\")\n",
        "                # Try basic save as fallback\n",
        "                try:\n",
        "                    output_doc.save(output_path)\n",
        "                    print(\"✅ Saved with basic options\")\n",
        "                    return True\n",
        "                except Exception as basic_error:\n",
        "                    print(f\"❌ Basic save failed: {basic_error}\")\n",
        "                    return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error during processing: {e}\")\n",
        "            import traceback\n",
        "            if self.debug_mode:\n",
        "                print(f\"🔍 Debug traceback:\\n{traceback.format_exc()}\")\n",
        "            return False\n",
        "\n",
        "        finally:\n",
        "            # Cleanup\n",
        "            if input_doc:\n",
        "                try:\n",
        "                    input_doc.close()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            if output_doc:\n",
        "                try:\n",
        "                    output_doc.close()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            gc.collect()\n",
        "\n",
        "    # =============================================================================\n",
        "    # 🎛️ USER INTERFACE AND CONTROL FUNCTIONS\n",
        "    # =============================================================================\n",
        "\n",
        "    def create_advanced_interface(self):\n",
        "        \"\"\"Create advanced user interface\"\"\"\n",
        "\n",
        "        print(\"🎛️ ADVANCED PDF SPLITTER INTERFACE\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Detection method selection\n",
        "        method_selector = widgets.Dropdown(\n",
        "            options=[\n",
        "                ('🎯 Multi-Method Analysis (Recommended)', 'multi_method'),\n",
        "                ('📏 Line Detection Only', 'line_detection'),\n",
        "                ('🧠 Content Analysis Only', 'content_analysis'),\n",
        "                ('👁️ Visual Analysis Only', 'visual_analysis'),\n",
        "                ('🔧 Custom Ratio', 'custom')\n",
        "            ],\n",
        "            value='multi_method',\n",
        "            description='Analysis Method:',\n",
        "            style={'description_width': '150px'},\n",
        "            layout={'width': '400px'}\n",
        "        )\n",
        "\n",
        "        # Custom ratio slider (hidden by default)\n",
        "        custom_ratio_slider = widgets.FloatSlider(\n",
        "            value=0.5,\n",
        "            min=0.1,\n",
        "            max=0.9,\n",
        "            step=0.01,\n",
        "            description='Custom Split Ratio:',\n",
        "            style={'description_width': '150px'},\n",
        "            readout_format='.0%',\n",
        "            layout={'width': '400px', 'display': 'none'}\n",
        "        )\n",
        "\n",
        "        # Advanced options\n",
        "        debug_checkbox = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Enable detailed analysis output',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        sample_pages_slider = widgets.IntSlider(\n",
        "            value=10,\n",
        "            min=1,\n",
        "            max=20,\n",
        "            description='Pages to analyze:',\n",
        "            style={'description_width': '150px'},\n",
        "            layout={'width': '400px'}\n",
        "        )\n",
        "\n",
        "        # Analysis results display\n",
        "        results_output = widgets.Output()\n",
        "\n",
        "        # Interactive elements\n",
        "        def on_method_change(change):\n",
        "            if change['new'] == 'custom':\n",
        "                custom_ratio_slider.layout.display = 'block'\n",
        "            else:\n",
        "                custom_ratio_slider.layout.display = 'none'\n",
        "\n",
        "        method_selector.observe(on_method_change, names='value')\n",
        "\n",
        "        # Layout\n",
        "        interface = widgets.VBox([\n",
        "            widgets.HTML(\"<h2>🎯 Advanced PDF Splitter Configuration</h2>\"),\n",
        "            widgets.HTML(\"<p>Select analysis method and configure options:</p>\"),\n",
        "            method_selector,\n",
        "            custom_ratio_slider,\n",
        "            debug_checkbox,\n",
        "            sample_pages_slider,\n",
        "            widgets.HTML(\"<hr>\"),\n",
        "            results_output\n",
        "        ])\n",
        "\n",
        "        display(interface)\n",
        "\n",
        "        return {\n",
        "            'method_selector': method_selector,\n",
        "            'custom_ratio_slider': custom_ratio_slider,\n",
        "            'debug_checkbox': debug_checkbox,\n",
        "            'sample_pages_slider': sample_pages_slider,\n",
        "            'results_output': results_output\n",
        "        }\n",
        "\n",
        "    def validate_pdf_file(self, pdf_path: str) -> Tuple[bool, str, Dict]:\n",
        "        \"\"\"Comprehensive PDF validation\"\"\"\n",
        "\n",
        "        try:\n",
        "            if not os.path.exists(pdf_path):\n",
        "                return False, \"❌ File not found\", {}\n",
        "\n",
        "            if not pdf_path.lower().endswith('.pdf'):\n",
        "                return False, \"❌ Not a PDF file\", {}\n",
        "\n",
        "            # Get file info\n",
        "            file_size = os.path.getsize(pdf_path) / (1024 * 1024)  # MB\n",
        "            file_modified = datetime.fromtimestamp(os.path.getmtime(pdf_path))\n",
        "\n",
        "            # Open and analyze PDF\n",
        "            doc = fitz.open(pdf_path)\n",
        "\n",
        "            try:\n",
        "                page_count = len(doc)\n",
        "\n",
        "                if page_count == 0:\n",
        "                    return False, \"❌ PDF has no pages\", {}\n",
        "\n",
        "                if doc.needs_pass:\n",
        "                    return False, \"❌ PDF is password protected\", {}\n",
        "\n",
        "                # Get detailed info\n",
        "                metadata = doc.metadata\n",
        "                first_page = doc[0]\n",
        "\n",
        "                pdf_info = {\n",
        "                    'file_size_mb': file_size,\n",
        "                    'page_count': page_count,\n",
        "                    'page_dimensions': {\n",
        "                        'width': first_page.rect.width,\n",
        "                        'height': first_page.rect.height,\n",
        "                        'aspect_ratio': first_page.rect.width / first_page.rect.height\n",
        "                    },\n",
        "                    'metadata': {\n",
        "                        'title': metadata.get('title', 'Unknown'),\n",
        "                        'author': metadata.get('author', 'Unknown'),\n",
        "                        'creator': metadata.get('creator', 'Unknown'),\n",
        "                        'producer': metadata.get('producer', 'Unknown')\n",
        "                    },\n",
        "                    'file_modified': file_modified.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    'estimated_processing_time': page_count * 0.1  # seconds\n",
        "                }\n",
        "\n",
        "                # Check for potential issues\n",
        "                warnings = []\n",
        "\n",
        "                if file_size > 50:  # Large file\n",
        "                    warnings.append(f\"⚠️ Large file ({file_size:.1f} MB) - processing may take longer\")\n",
        "\n",
        "                if page_count > 100:\n",
        "                    warnings.append(f\"⚠️ Many pages ({page_count}) - consider processing in batches\")\n",
        "\n",
        "                if first_page.rect.width / first_page.rect.height < 1.2:\n",
        "                    warnings.append(\"⚠️ Pages seem narrow - vertical split may not be optimal\")\n",
        "\n",
        "                success_message = f\"✅ Valid PDF: {page_count} pages, {file_size:.1f} MB\"\n",
        "                if warnings:\n",
        "                    success_message += f\"\\n   {'   '.join(warnings)}\"\n",
        "\n",
        "                return True, success_message, pdf_info\n",
        "\n",
        "            finally:\n",
        "                doc.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            return False, f\"❌ Error analyzing PDF: {str(e)}\", {}\n",
        "\n",
        "    def download_with_retry(self, file_path: str, max_retries: int = 3) -> bool:\n",
        "        \"\"\"Download file with retry logic and better error handling\"\"\"\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"❌ File not found: {file_path}\")\n",
        "            return False\n",
        "\n",
        "        file_size = os.path.getsize(file_path) / (1024 * 1024)\n",
        "        print(f\"📥 Preparing download: {os.path.basename(file_path)} ({file_size:.2f} MB)\")\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                print(f\"   Attempt {attempt + 1}/{max_retries}...\")\n",
        "                files.download(file_path)\n",
        "                print(\"✅ Download successful!\")\n",
        "                return True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ Attempt {attempt + 1} failed: {str(e)[:100]}\")\n",
        "\n",
        "                if attempt < max_retries - 1:\n",
        "                    wait_time = (attempt + 1) * 2  # Progressive wait\n",
        "                    print(f\"   ⏳ Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"❌ All download attempts failed\")\n",
        "                    print(f\"💡 File is still available locally: {file_path}\")\n",
        "                    return False\n",
        "\n",
        "        return False\n",
        "\n",
        "# =============================================================================\n",
        "# 🚀 MAIN EXECUTION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def test_comprehensive_analysis():\n",
        "    \"\"\"Test comprehensive analysis on uploaded PDF\"\"\"\n",
        "\n",
        "    print(\"🧪 COMPREHENSIVE PDF ANALYSIS TEST\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"🕐 Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Find PDF files\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith(('SMART_', 'LINE_', 'PRECISION_'))]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found.\")\n",
        "        print(\"💡 Please upload a PDF file first.\")\n",
        "        return None\n",
        "\n",
        "    pdf_file = pdf_files[0]\n",
        "    print(f\"📁 Analyzing: {pdf_file}\")\n",
        "\n",
        "    # Create splitter instance\n",
        "    splitter = CompletePDFSplitter()\n",
        "\n",
        "    # Validate PDF\n",
        "    is_valid, message, pdf_info = splitter.validate_pdf_file(pdf_file)\n",
        "    print(f\"\\n📋 PDF Validation:\")\n",
        "    print(message)\n",
        "\n",
        "    if not is_valid:\n",
        "        return None\n",
        "\n",
        "    if pdf_info:\n",
        "        print(f\"\\n📊 PDF Information:\")\n",
        "        print(f\"   • Pages: {pdf_info['page_count']}\")\n",
        "        print(f\"   • Size: {pdf_info['file_size_mb']:.2f} MB\")\n",
        "        print(f\"   • Dimensions: {pdf_info['page_dimensions']['width']:.0f} x {pdf_info['page_dimensions']['height']:.0f}\")\n",
        "        print(f\"   • Aspect ratio: {pdf_info['page_dimensions']['aspect_ratio']:.2f}\")\n",
        "        print(f\"   • Estimated processing time: {pdf_info['estimated_processing_time']:.1f} seconds\")\n",
        "\n",
        "    # Run comprehensive analysis\n",
        "    print(f\"\\n🔍 Running Comprehensive Analysis...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    analysis_result = splitter.detect_optimal_split_multi_method(pdf_file)\n",
        "\n",
        "    # Display detailed results\n",
        "    print(f\"\\n📊 COMPREHENSIVE ANALYSIS RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"🎯 Optimal Split Ratio: {analysis_result['optimal_split']:.1%}\")\n",
        "    print(f\"🔒 Overall Confidence: {analysis_result['confidence']:.1%}\")\n",
        "    print(f\"🤝 Methods Agreement: {analysis_result.get('agreement_factor', 0):.1%}\")\n",
        "\n",
        "    if 'summary' in analysis_result:\n",
        "        summary = analysis_result['summary']\n",
        "        print(f\"\\n📋 Individual Method Confidences:\")\n",
        "        print(f\"   📏 Line Detection: {summary.get('line_detection_confidence', 0):.1%}\")\n",
        "        print(f\"   🧠 Content Analysis: {summary.get('content_analysis_confidence', 0):.1%}\")\n",
        "        print(f\"   👁️ Visual Analysis: {summary.get('visual_analysis_confidence', 0):.1%}\")\n",
        "        print(f\"   📋 Structure Analysis: {summary.get('structure_analysis_confidence', 0):.1%}\")\n",
        "\n",
        "    # Recommendations\n",
        "    confidence = analysis_result['confidence']\n",
        "    split_ratio = analysis_result['optimal_split']\n",
        "\n",
        "    print(f\"\\n💡 RECOMMENDATIONS:\")\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    if confidence > 0.8:\n",
        "        print(\"🟢 EXCELLENT: Very high confidence in detection\")\n",
        "        print(f\"   ✅ Proceed with split at {split_ratio:.1%}\")\n",
        "    elif confidence > 0.6:\n",
        "        print(\"🟡 GOOD: High confidence in detection\")\n",
        "        print(f\"   ✅ Recommended split at {split_ratio:.1%}\")\n",
        "    elif confidence > 0.4:\n",
        "        print(\"🟠 MODERATE: Moderate confidence\")\n",
        "        print(f\"   ⚠️ Consider manual review of {split_ratio:.1%} split\")\n",
        "    else:\n",
        "        print(\"🔴 LOW: Low confidence in detection\")\n",
        "        print(f\"   ⚠️ Manual inspection recommended\")\n",
        "        print(f\"   💭 Suggested fallback: {split_ratio:.1%}\")\n",
        "\n",
        "    # Special cases\n",
        "    if split_ratio < 0.25 or split_ratio > 0.75:\n",
        "        print(f\"   ⚠️ Unusual split ratio detected: {split_ratio:.1%}\")\n",
        "        print(\"   💭 This might indicate special document layout\")\n",
        "\n",
        "    return analysis_result\n",
        "\n",
        "def run_intelligent_split():\n",
        "    \"\"\"Run intelligent PDF splitting with comprehensive analysis\"\"\"\n",
        "\n",
        "    print(\"🎯 INTELLIGENT PDF SPLITTER v4.0\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"🧠 Complete Multi-Method Analysis System\")\n",
        "    print(f\"🕐 Session: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Find PDF files\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith(('SMART_', 'LINE_', 'PRECISION_'))]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found.\")\n",
        "        print(\"💡 Please upload a PDF file first.\")\n",
        "        return\n",
        "\n",
        "    pdf_file = pdf_files[0]\n",
        "\n",
        "    # Create splitter\n",
        "    splitter = CompletePDFSplitter()\n",
        "\n",
        "    # Generate output filename\n",
        "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "    output_file = f\"INTELLIGENT_SPLIT_{Path(pdf_file).stem}_{timestamp}.pdf\"\n",
        "\n",
        "    print(f\"📁 Input: {pdf_file}\")\n",
        "    print(f\"📁 Output: {output_file}\")\n",
        "\n",
        "    # Process with comprehensive analysis\n",
        "    success = splitter.split_pdf_with_analysis(pdf_file, output_file, \"multi_method\")\n",
        "\n",
        "    if success:\n",
        "        print(f\"\\n🎉 SUCCESS! PDF split completed.\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        # Attempt download\n",
        "        if splitter.download_with_retry(output_file):\n",
        "            print(\"✅ File downloaded successfully!\")\n",
        "        else:\n",
        "            print(\"⚠️ Download failed, but file is ready locally\")\n",
        "def run_interactive_mode():\n",
        "    \"\"\"Run interactive mode with step-by-step guidance\"\"\"\n",
        "\n",
        "    print(\"🎮 INTERACTIVE PDF SPLITTER MODE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"🕐 Current Time: 2025-08-08 12:22:52 UTC\")\n",
        "    print(f\"👤 Current User: Ravi-katta-dev\")\n",
        "    print(\"🎯 Interactive Step-by-Step Processing\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create splitter instance\n",
        "    splitter = CompletePDFSplitter()\n",
        "\n",
        "    # Step 1: Find and validate PDF\n",
        "    print(\"\\n📋 STEP 1: PDF Discovery and Validation\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith(('SMART_', 'LINE_', 'PRECISION_', 'INTELLIGENT_'))]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found in current directory.\")\n",
        "        print(\"\\n💡 To upload a PDF:\")\n",
        "        print(\"   1. Click the 📁 folder icon in the left sidebar\")\n",
        "        print(\"   2. Select 'Upload to session storage'\")\n",
        "        print(\"   3. Choose your PDF file\")\n",
        "        print(\"   4. Wait for upload to complete\")\n",
        "        print(\"   5. Re-run this function\")\n",
        "        return\n",
        "\n",
        "    print(f\"✅ Found PDF files:\")\n",
        "    for i, pdf in enumerate(pdf_files, 1):\n",
        "        file_size = os.path.getsize(pdf) / (1024 * 1024)\n",
        "        print(f\"   {i}. {pdf} ({file_size:.2f} MB)\")\n",
        "\n",
        "    # Use first PDF\n",
        "    selected_pdf = pdf_files[0]\n",
        "    print(f\"\\n🎯 Selected: {selected_pdf}\")\n",
        "\n",
        "    # Validate PDF\n",
        "    is_valid, validation_message, pdf_info = splitter.validate_pdf_file(selected_pdf)\n",
        "    print(f\"\\n📊 Validation Result:\")\n",
        "    print(validation_message)\n",
        "\n",
        "    if not is_valid:\n",
        "        print(\"❌ Cannot proceed with invalid PDF.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Quick Analysis Preview\n",
        "    print(f\"\\n🔍 STEP 2: Quick Analysis Preview\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    print(\"Running quick line detection preview...\")\n",
        "    quick_analysis = splitter.detect_vertical_lines(selected_pdf, sample_pages=3)\n",
        "\n",
        "    quick_split = quick_analysis.get('optimal_split', 0.5)\n",
        "    quick_confidence = quick_analysis.get('confidence', 0.1)\n",
        "\n",
        "    print(f\"📏 Quick line detection result:\")\n",
        "    print(f\"   • Suggested split: {quick_split:.1%}\")\n",
        "    print(f\"   • Confidence: {quick_confidence:.1%}\")\n",
        "\n",
        "    if quick_confidence > 0.6:\n",
        "        print(\"✅ High confidence - line detection working well!\")\n",
        "    elif quick_confidence > 0.3:\n",
        "        print(\"⚠️ Moderate confidence - will use comprehensive analysis\")\n",
        "    else:\n",
        "        print(\"❌ Low confidence - will run full multi-method analysis\")\n",
        "\n",
        "    # Step 3: User Decision Point\n",
        "    print(f\"\\n🤔 STEP 3: Processing Decision\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if quick_confidence > 0.7:\n",
        "        print(\"🚀 RECOMMENDATION: Use quick line detection\")\n",
        "        print(f\"   Split ratio: {quick_split:.1%}\")\n",
        "        print(\"   This should work perfectly for your PDF!\")\n",
        "        recommended_method = \"line_detection\"\n",
        "    else:\n",
        "        print(\"🧠 RECOMMENDATION: Use comprehensive multi-method analysis\")\n",
        "        print(\"   This will analyze your PDF using all available methods\")\n",
        "        recommended_method = \"multi_method\"\n",
        "\n",
        "    print(f\"\\n📝 Available options:\")\n",
        "    print(\"   1. 🚀 Use recommended method (fastest)\")\n",
        "    print(\"   2. 🧠 Force comprehensive analysis (most accurate)\")\n",
        "    print(\"   3. 📏 Line detection only\")\n",
        "    print(\"   4. 🎛️ Custom ratio\")\n",
        "    print(\"   5. 🧪 Test all methods (analysis only)\")\n",
        "\n",
        "    # Auto-select recommended method for demo\n",
        "    choice = \"1\"  # Simulating user choosing recommended method\n",
        "    print(f\"🎯 Auto-selecting option 1 (recommended method)\")\n",
        "\n",
        "    # Step 4: Execute Processing\n",
        "    print(f\"\\n⚙️ STEP 4: Processing Execution\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Generate output filename\n",
        "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        method = recommended_method\n",
        "        output_file = f\"SMART_SPLIT_{Path(selected_pdf).stem}_{timestamp}.pdf\"\n",
        "    elif choice == \"2\":\n",
        "        method = \"multi_method\"\n",
        "        output_file = f\"COMPREHENSIVE_SPLIT_{Path(selected_pdf).stem}_{timestamp}.pdf\"\n",
        "    elif choice == \"3\":\n",
        "        method = \"line_detection\"\n",
        "        output_file = f\"LINE_SPLIT_{Path(selected_pdf).stem}_{timestamp}.pdf\"\n",
        "    elif choice == \"4\":\n",
        "        # Custom ratio would be handled here\n",
        "        custom_ratio = 0.6  # Example\n",
        "        method = \"custom\"\n",
        "        output_file = f\"CUSTOM_SPLIT_{Path(selected_pdf).stem}_{timestamp}.pdf\"\n",
        "    else:\n",
        "        # Test mode\n",
        "        print(\"🧪 Running comprehensive test...\")\n",
        "        test_result = test_comprehensive_analysis()\n",
        "        print(\"✅ Test completed! Check results above.\")\n",
        "        return\n",
        "\n",
        "    print(f\"📁 Output file: {output_file}\")\n",
        "    print(f\"🔧 Processing method: {method}\")\n",
        "\n",
        "    # Execute the split\n",
        "    print(f\"\\n🚀 Starting processing...\")\n",
        "    success = splitter.split_pdf_with_analysis(selected_pdf, output_file, method)\n",
        "\n",
        "    # Step 5: Results and Download\n",
        "    print(f\"\\n📦 STEP 5: Results and Download\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if success:\n",
        "        print(\"🎉 SUCCESS! PDF processing completed.\")\n",
        "\n",
        "        # File statistics\n",
        "        if os.path.exists(output_file):\n",
        "            output_size = os.path.getsize(output_file) / (1024 * 1024)\n",
        "            input_size = os.path.getsize(selected_pdf) / (1024 * 1024)\n",
        "\n",
        "            print(f\"\\n📊 File Statistics:\")\n",
        "            print(f\"   • Input size: {input_size:.2f} MB\")\n",
        "            print(f\"   • Output size: {output_size:.2f} MB\")\n",
        "            print(f\"   • Size efficiency: {(1 - output_size/input_size):.1%} reduction\")\n",
        "\n",
        "        # Attempt download\n",
        "        print(f\"\\n📥 Attempting download...\")\n",
        "        download_success = splitter.download_with_retry(output_file, max_retries=3)\n",
        "\n",
        "        if download_success:\n",
        "            print(\"✅ Download completed successfully!\")\n",
        "            print(f\"💾 Your split PDF has been downloaded: {output_file}\")\n",
        "        else:\n",
        "            print(\"⚠️ Download failed, but processing was successful\")\n",
        "            print(f\"💡 File is available locally: {output_file}\")\n",
        "            print(\"🔄 You can try downloading manually or re-run the download\")\n",
        "    else:\n",
        "        print(\"❌ Processing failed. Please check the error messages above.\")\n",
        "\n",
        "        # Troubleshooting suggestions\n",
        "        print(f\"\\n🔧 Troubleshooting suggestions:\")\n",
        "        print(\"   1. Check if PDF is valid and not corrupted\")\n",
        "        print(\"   2. Try restarting the runtime (Runtime → Restart Runtime)\")\n",
        "        print(\"   3. Re-upload the PDF file\")\n",
        "        print(\"   4. Try a different processing method\")\n",
        "\n",
        "    print(f\"\\n✅ Interactive session completed!\")\n",
        "    print(f\"🕐 Session ended: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n",
        "\n",
        "def quick_split_now():\n",
        "    \"\"\"Quick split with minimal setup - just process and download\"\"\"\n",
        "\n",
        "    print(\"⚡ QUICK SPLIT - FAST PROCESSING\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"🕐 Time: 2025-08-08 12:22:52 UTC\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "    print(\"⚡ Fast processing with smart defaults\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Find PDF\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith(('SMART_', 'LINE_', 'PRECISION_', 'INTELLIGENT_', 'COMPREHENSIVE_', 'CUSTOM_'))]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found.\")\n",
        "        return\n",
        "\n",
        "    pdf_file = pdf_files[0]\n",
        "    print(f\"📁 Processing: {pdf_file}\")\n",
        "\n",
        "    # Quick validation\n",
        "    if not os.path.exists(pdf_file):\n",
        "        print(\"❌ File not found.\")\n",
        "        return\n",
        "\n",
        "    file_size = os.path.getsize(pdf_file) / (1024 * 1024)\n",
        "    print(f\"📊 File size: {file_size:.2f} MB\")\n",
        "\n",
        "    # Create splitter and process\n",
        "    splitter = CompletePDFSplitter()\n",
        "    splitter.debug_mode = False  # Reduce output for quick mode\n",
        "\n",
        "    # Generate output\n",
        "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "    output_file = f\"QUICK_SPLIT_{Path(pdf_file).stem}_{timestamp}.pdf\"\n",
        "\n",
        "    print(f\"🚀 Quick processing...\")\n",
        "\n",
        "    # Use multi-method for best results\n",
        "    success = splitter.split_pdf_with_analysis(pdf_file, output_file, \"multi_method\")\n",
        "\n",
        "    if success:\n",
        "        print(f\"✅ Done! Downloading {output_file}...\")\n",
        "\n",
        "        try:\n",
        "            files.download(output_file)\n",
        "            print(\"🎉 Success! Your split PDF has been downloaded.\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Download error: {e}\")\n",
        "            print(f\"💡 File saved as: {output_file}\")\n",
        "    else:\n",
        "        print(\"❌ Processing failed.\")\n",
        "\n",
        "def batch_process_pdfs():\n",
        "    \"\"\"Process multiple PDFs if available\"\"\"\n",
        "\n",
        "    print(\"📦 BATCH PDF PROCESSING\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"🕐 Time: 2025-08-08 12:22:52 UTC\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "    print(\"📦 Process multiple PDFs automatically\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Find all PDFs\n",
        "    all_pdfs = [f for f in os.listdir('.') if f.lower().endswith('.pdf')]\n",
        "    input_pdfs = [f for f in all_pdfs if not f.startswith(('SMART_', 'LINE_', 'PRECISION_', 'INTELLIGENT_', 'COMPREHENSIVE_', 'CUSTOM_', 'QUICK_'))]\n",
        "\n",
        "    if not input_pdfs:\n",
        "        print(\"❌ No input PDF files found.\")\n",
        "        return\n",
        "\n",
        "    if len(input_pdfs) == 1:\n",
        "        print(f\"📄 Only one PDF found: {input_pdfs[0]}\")\n",
        "        print(\"💡 Use quick_split_now() for single file processing\")\n",
        "        return\n",
        "\n",
        "    print(f\"📚 Found {len(input_pdfs)} PDFs to process:\")\n",
        "    for i, pdf in enumerate(input_pdfs, 1):\n",
        "        file_size = os.path.getsize(pdf) / (1024 * 1024)\n",
        "        print(f\"   {i}. {pdf} ({file_size:.2f} MB)\")\n",
        "\n",
        "    # Create splitter\n",
        "    splitter = CompletePDFSplitter()\n",
        "\n",
        "    # Process each PDF\n",
        "    successful_files = []\n",
        "    failed_files = []\n",
        "\n",
        "    for i, pdf_file in enumerate(input_pdfs, 1):\n",
        "        print(f\"\\n🔄 Processing {i}/{len(input_pdfs)}: {pdf_file}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Generate output name\n",
        "        timestamp = datetime.now().strftime(\"%H%M%S\")\n",
        "        output_file = f\"BATCH_SPLIT_{i}_{Path(pdf_file).stem}_{timestamp}.pdf\"\n",
        "\n",
        "        try:\n",
        "            success = splitter.split_pdf_with_analysis(pdf_file, output_file, \"multi_method\")\n",
        "\n",
        "            if success:\n",
        "                successful_files.append(output_file)\n",
        "                print(f\"✅ {pdf_file} processed successfully\")\n",
        "            else:\n",
        "                failed_files.append(pdf_file)\n",
        "                print(f\"❌ {pdf_file} processing failed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            failed_files.append(pdf_file)\n",
        "            print(f\"❌ {pdf_file} error: {e}\")\n",
        "\n",
        "    # Results summary\n",
        "    print(f\"\\n📊 BATCH PROCESSING SUMMARY\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"✅ Successful: {len(successful_files)}/{len(input_pdfs)}\")\n",
        "    print(f\"❌ Failed: {len(failed_files)}/{len(input_pdfs)}\")\n",
        "\n",
        "    if successful_files:\n",
        "        print(f\"\\n📥 Downloading successful files...\")\n",
        "\n",
        "        for output_file in successful_files:\n",
        "            try:\n",
        "                files.download(output_file)\n",
        "                print(f\"✅ Downloaded: {output_file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Download failed: {output_file} - {e}\")\n",
        "\n",
        "    if failed_files:\n",
        "        print(f\"\\n❌ Failed files:\")\n",
        "        for failed_file in failed_files:\n",
        "            print(f\"   • {failed_file}\")\n",
        "\n",
        "def diagnose_pdf_issues():\n",
        "    \"\"\"Diagnose potential issues with PDF processing\"\"\"\n",
        "\n",
        "    print(\"🔍 PDF DIAGNOSTIC TOOL\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"🕐 Time: 2025-08-08 12:22:52 UTC\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "    print(\"🔍 Comprehensive PDF analysis and issue detection\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Find PDFs\n",
        "    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf') and not f.startswith(('SMART_', 'LINE_', 'PRECISION_', 'INTELLIGENT_'))]\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"❌ No PDF files found for diagnosis.\")\n",
        "        return\n",
        "\n",
        "    splitter = CompletePDFSplitter()\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"\\n🔍 DIAGNOSING: {pdf_file}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Basic file info\n",
        "        try:\n",
        "            file_size = os.path.getsize(pdf_file) / (1024 * 1024)\n",
        "            print(f\"📁 File size: {file_size:.2f} MB\")\n",
        "\n",
        "            # Detailed validation\n",
        "            is_valid, message, pdf_info = splitter.validate_pdf_file(pdf_file)\n",
        "            print(f\"📋 Validation: {message}\")\n",
        "\n",
        "            if not is_valid:\n",
        "                continue\n",
        "\n",
        "            # Open PDF for detailed analysis\n",
        "            doc = fitz.open(pdf_file)\n",
        "\n",
        "            try:\n",
        "                # Page analysis\n",
        "                print(f\"\\n📄 Page Analysis:\")\n",
        "                print(f\"   • Total pages: {len(doc)}\")\n",
        "\n",
        "                if len(doc) > 0:\n",
        "                    first_page = doc[0]\n",
        "                    print(f\"   • Page size: {first_page.rect.width:.0f} x {first_page.rect.height:.0f}\")\n",
        "                    print(f\"   • Aspect ratio: {first_page.rect.width/first_page.rect.height:.2f}\")\n",
        "\n",
        "                    # Text analysis\n",
        "                    text_content = first_page.get_text()\n",
        "                    print(f\"   • Text length (first page): {len(text_content)} characters\")\n",
        "\n",
        "                    if len(text_content) < 50:\n",
        "                        print(\"   ⚠️ Warning: Very little text detected\")\n",
        "\n",
        "                    # Check for common keywords\n",
        "                    keywords = ['question', 'answer', 'telegram', 'click', 'practice', 'exam']\n",
        "                    found_keywords = [kw for kw in keywords if kw.lower() in text_content.lower()]\n",
        "\n",
        "                    if found_keywords:\n",
        "                        print(f\"   • Content type indicators: {', '.join(found_keywords)}\")\n",
        "\n",
        "                # Quick line detection test\n",
        "                print(f\"\\n📏 Line Detection Test:\")\n",
        "                line_test = splitter.detect_vertical_lines(pdf_file, sample_pages=3)\n",
        "\n",
        "                print(f\"   • Lines detected: {len(line_test.get('detected_lines', []))}\")\n",
        "                print(f\"   • Suggested split: {line_test.get('optimal_split', 0.5):.1%}\")\n",
        "                print(f\"   • Confidence: {line_test.get('confidence', 0):.1%}\")\n",
        "\n",
        "                if line_test.get('confidence', 0) > 0.7:\n",
        "                    print(\"   ✅ Excellent line detection\")\n",
        "                elif line_test.get('confidence', 0) > 0.4:\n",
        "                    print(\"   ⚠️ Moderate line detection\")\n",
        "                else:\n",
        "                    print(\"   ❌ Poor line detection - may need manual ratio\")\n",
        "\n",
        "                # Content structure analysis\n",
        "                print(f\"\\n🧠 Content Structure:\")\n",
        "\n",
        "                blocks = first_page.get_text(\"dict\").get(\"blocks\", [])\n",
        "                text_blocks = [b for b in blocks if \"lines\" in b]\n",
        "\n",
        "                print(f\"   • Text blocks: {len(text_blocks)}\")\n",
        "\n",
        "                if text_blocks:\n",
        "                    x_positions = []\n",
        "                    for block in text_blocks:\n",
        "                        bbox = block[\"bbox\"]\n",
        "                        x_positions.extend([bbox[0], bbox[2]])\n",
        "\n",
        "                    x_positions.sort()\n",
        "                    page_width = first_page.rect.width\n",
        "\n",
        "                    # Check distribution\n",
        "                    left_content = sum(1 for x in x_positions if x < page_width * 0.5)\n",
        "                    right_content = sum(1 for x in x_positions if x >= page_width * 0.5)\n",
        "\n",
        "                    print(f\"   • Content distribution: {left_content} left, {right_content} right\")\n",
        "\n",
        "                    if abs(left_content - right_content) > 5:\n",
        "                        print(\"   ✅ Uneven distribution - good for splitting\")\n",
        "                    else:\n",
        "                        print(\"   ⚠️ Even distribution - splitting may not be beneficial\")\n",
        "\n",
        "                # Recommendations\n",
        "                print(f\"\\n💡 RECOMMENDATIONS:\")\n",
        "\n",
        "                confidence = line_test.get('confidence', 0)\n",
        "                split_ratio = line_test.get('optimal_split', 0.5)\n",
        "\n",
        "                if confidence > 0.7:\n",
        "                    print(f\"   🟢 PROCEED: Use automatic detection ({split_ratio:.1%})\")\n",
        "                elif confidence > 0.4:\n",
        "                    print(f\"   🟡 CAUTION: Review suggested split ({split_ratio:.1%})\")\n",
        "                else:\n",
        "                    print(f\"   🔴 MANUAL: Consider manual inspection\")\n",
        "\n",
        "                # Check for potential issues\n",
        "                issues = []\n",
        "\n",
        "                if file_size > 100:\n",
        "                    issues.append(\"Very large file - processing may be slow\")\n",
        "\n",
        "                if len(doc) > 200:\n",
        "                    issues.append(\"Many pages - consider batch processing\")\n",
        "\n",
        "                if split_ratio < 0.2 or split_ratio > 0.8:\n",
        "                    issues.append(f\"Unusual split ratio ({split_ratio:.1%})\")\n",
        "\n",
        "                if len(text_content) < 100:\n",
        "                    issues.append(\"Very little text - might be image-based PDF\")\n",
        "\n",
        "                if issues:\n",
        "                    print(f\"\\n⚠️ POTENTIAL ISSUES:\")\n",
        "                    for issue in issues:\n",
        "                        print(f\"   • {issue}\")\n",
        "                else:\n",
        "                    print(f\"\\n✅ No issues detected - PDF looks good for processing!\")\n",
        "\n",
        "            finally:\n",
        "                doc.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Diagnostic error: {e}\")\n",
        "\n",
        "def show_help_and_usage():\n",
        "    \"\"\"Show comprehensive help and usage guide\"\"\"\n",
        "\n",
        "    print(\"📚 COMPLETE PDF SPLITTER - HELP & USAGE GUIDE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"🕐 Time: 2025-08-08 12:22:52 UTC\")\n",
        "    print(f\"👤 User: Ravi-katta-dev\")\n",
        "    print(f\"📱 Session: {datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\"\"\n",
        "🎯 AVAILABLE FUNCTIONS:\n",
        "\n",
        "1. 🚀 QUICK PROCESSING:\n",
        "   quick_split_now()                    - Fast split with smart defaults\n",
        "\n",
        "2. 🎮 INTERACTIVE MODE:\n",
        "   run_interactive_mode()               - Step-by-step guided processing\n",
        "\n",
        "3. 🧠 COMPREHENSIVE ANALYSIS:\n",
        "   test_comprehensive_analysis()        - Test all detection methods\n",
        "   run_intelligent_split()              - Full multi-method processing\n",
        "\n",
        "4. 📦 BATCH PROCESSING:\n",
        "   batch_process_pdfs()                 - Process multiple PDFs\n",
        "\n",
        "5. 🔍 DIAGNOSTIC TOOLS:\n",
        "   diagnose_pdf_issues()                - Analyze PDF structure and issues\n",
        "\n",
        "6. ℹ️ HELP & INFO:\n",
        "   show_help_and_usage()                - This help guide\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════\n",
        "\n",
        "🎯 RECOMMENDED WORKFLOW:\n",
        "\n",
        "For First-Time Users:\n",
        "1. Upload your PDF file\n",
        "2. Run: diagnose_pdf_issues()          # Check for any issues\n",
        "3. Run: test_comprehensive_analysis()   # See what methods work best\n",
        "4. Run: run_interactive_mode()         # Process with guidance\n",
        "\n",
        "For Quick Processing:\n",
        "1. Upload your PDF file\n",
        "2. Run: quick_split_now()              # Fast processing\n",
        "\n",
        "For Multiple Files:\n",
        "1. Upload multiple PDF files\n",
        "2. Run: batch_process_pdfs()           # Process all at once\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════\n",
        "\n",
        "🔧 DETECTION METHODS:\n",
        "\n",
        "📏 Line Detection:\n",
        "   - Finds actual vertical lines in your PDF\n",
        "   - Perfect for documents with visible dividers\n",
        "   - High accuracy for structured documents\n",
        "\n",
        "🧠 Content Analysis:\n",
        "   - Analyzes text density and distribution\n",
        "   - Good for documents without visible lines\n",
        "   - Works with natural content boundaries\n",
        "\n",
        "👁️ Visual Pattern Recognition:\n",
        "   - Recognizes visual layout patterns\n",
        "   - Detects column structures and alignments\n",
        "   - Useful for complex layouts\n",
        "\n",
        "📋 Document Structure Analysis:\n",
        "   - Understands document type and purpose\n",
        "   - Optimizes for exam papers, forms, etc.\n",
        "   - Context-aware processing\n",
        "\n",
        "🎯 Multi-Method Fusion:\n",
        "   - Combines all methods for best accuracy\n",
        "   - Highest confidence results\n",
        "   - Recommended for unknown document types\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════\n",
        "\n",
        "💡 TROUBLESHOOTING:\n",
        "\n",
        "❌ \"No PDF files found\":\n",
        "   - Upload a PDF file first\n",
        "   - Check file has .pdf extension\n",
        "   - Restart runtime if needed\n",
        "\n",
        "❌ \"Processing failed\":\n",
        "   - Run diagnose_pdf_issues() to check PDF\n",
        "   - Try different detection method\n",
        "   - Check if PDF is password protected\n",
        "\n",
        "❌ \"Download failed\":\n",
        "   - File is still processed locally\n",
        "   - Try downloading manually\n",
        "   - Check internet connection\n",
        "\n",
        "❌ \"Low confidence detection\":\n",
        "   - PDF might have unusual layout\n",
        "   - Try manual ratio adjustment\n",
        "   - Use visual inspection\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════\n",
        "\n",
        "🎓 TIPS FOR BEST RESULTS:\n",
        "\n",
        "✅ PDF Quality:\n",
        "   - Use high-quality, text-based PDFs\n",
        "   - Avoid heavily compressed files\n",
        "   - Ensure text is selectable\n",
        "\n",
        "✅ Document Type:\n",
        "   - Works best with structured documents\n",
        "   - Exam papers, forms, and reports ideal\n",
        "   - Two-column layouts process excellently\n",
        "\n",
        "✅ File Size:\n",
        "   - Files under 50MB process fastest\n",
        "   - Large files may take longer\n",
        "   - Consider batch processing for multiple files\n",
        "\n",
        "✅ Split Ratios:\n",
        "   - 40-60% typically work best\n",
        "   - Extreme ratios (20% or 80%) may indicate issues\n",
        "   - Trust high-confidence detections\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════\n",
        "\n",
        "🆘 SUPPORT:\n",
        "\n",
        "If you encounter issues:\n",
        "1. Run diagnose_pdf_issues() first\n",
        "2. Check the troubleshooting section above\n",
        "3. Try different processing methods\n",
        "4. Consider manual ratio adjustment\n",
        "\n",
        "For best results with your exam papers:\n",
        "- Use quick_split_now() for simple cases\n",
        "- Use run_interactive_mode() for guidance\n",
        "- Use test_comprehensive_analysis() to verify detection\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════\n",
        "\"\"\")\n",
        "\n",
        "# =============================================================================\n",
        "# 🚀 SYSTEM INITIALIZATION AND STATUS\n",
        "# =============================================================================\n",
        "\n",
        "def system_status():\n",
        "    \"\"\"Show current system status and available files\"\"\"\n",
        "\n",
        "    print(\"📊 SYSTEM STATUS REPORT\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"🕐 Current Time: 2025-08-08 12:22:52 UTC\")\n",
        "    print(f\"👤 Current User: Ravi-katta-dev\")\n",
        "    print(f\"🐍 Python Environment: Google Colab\")\n",
        "    print(f\"📦 PyMuPDF Version: {fitz.version[0] if hasattr(fitz, 'version') else 'Unknown'}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Check current directory contents\n",
        "    all_files = os.listdir('.')\n",
        "    pdf_files = [f for f in all_files if f.lower().endswith('.pdf')]\n",
        "\n",
        "    print(f\"📁 Current Directory Analysis:\")\n",
        "    print(f\"   • Total files: {len(all_files)}\")\n",
        "    print(f\"   • PDF files: {len(pdf_files)}\")\n",
        "\n",
        "    if pdf_files:\n",
        "        print(f\"\\n📋 PDF Files Found:\")\n",
        "\n",
        "        input_pdfs = []\n",
        "        output_pdfs = []\n",
        "\n",
        "        for pdf in pdf_files:\n",
        "            file_size = os.path.getsize(pdf) / (1024 * 1024)\n",
        "\n",
        "            if pdf.startswith(('SMART_', 'LINE_', 'PRECISION_', 'INTELLIGENT_', 'COMPREHENSIVE_', 'CUSTOM_', 'QUICK_', 'BATCH_')):\n",
        "                output_pdfs.append((pdf, file_size))\n",
        "            else:\n",
        "                input_pdfs.append((pdf, file_size))\n",
        "\n",
        "        if input_pdfs:\n",
        "            print(f\"\\n📥 Input PDFs ({len(input_pdfs)}):\")\n",
        "            for pdf, size in input_pdfs:\n",
        "                print(f\"   📄 {pdf} ({size:.2f} MB)\")\n",
        "\n",
        "        if output_pdfs:\n",
        "            print(f\"\\n📤 Processed PDFs ({len(output_pdfs)}):\")\n",
        "            for pdf, size in output_pdfs:\n",
        "                print(f\"   📄 {pdf} ({size:.2f} MB)\")\n",
        "    else:\n",
        "        print(\"\\n❌ No PDF files found\")\n",
        "        print(\"💡 Upload a PDF file to get started\")\n",
        "\n",
        "    # Memory status\n",
        "    print(f\"\\n💾 Memory Status:\")\n",
        "    try:\n",
        "        import psutil\n",
        "        memory = psutil.virtual_memory()\n",
        "        print(f\"   • Available: {memory.available / (1024**3):.1f} GB\")\n",
        "        print(f\"   • Usage: {memory.percent:.1f}%\")\n",
        "    except:\n",
        "        print(\"   • Memory info not available\")\n",
        "\n",
        "    # Recommendations\n",
        "    print(f\"\\n💡 RECOMMENDATIONS:\")\n",
        "\n",
        "    if not pdf_files:\n",
        "        print(\"   🔸 Upload a PDF file first\")\n",
        "        print(\"   🔸 Run show_help_and_usage() for guidance\")\n",
        "    elif input_pdfs and not output_pdfs:\n",
        "        print(\"   🔸 Ready to process! Try quick_split_now()\")\n",
        "        print(\"   🔸 Or run run_interactive_mode() for guided processing\")\n",
        "    elif input_pdfs and output_pdfs:\n",
        "        print(\"   🔸 Some files already processed\")\n",
        "        print(\"   🔸 Check output files or process remaining inputs\")\n",
        "    else:\n",
        "        print(\"   🔸 Only output files found\")\n",
        "        print(\"   🔸 Upload new input PDFs or download existing outputs\")\n",
        "\n",
        "# Initialize the complete system\n",
        "print(\"🎯 COMPLETE PDF SPLITTER v4.0 - FULLY LOADED!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"🕐 System Time: 2025-08-08 12:22:52 UTC\")\n",
        "print(f\"👤 Current User: Ravi-katta-dev\")\n",
        "print(f\"🚀 Status: All systems operational\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Show system status\n",
        "system_status()\n",
        "\n",
        "print(f\"\\n🎮 QUICK START COMMANDS:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"🚀 quick_split_now()              # Fast processing\")\n",
        "print(\"🎮 run_interactive_mode()         # Step-by-step guidance\")\n",
        "print(\"🧪 test_comprehensive_analysis()  # Test all methods\")\n",
        "print(\"🔍 diagnose_pdf_issues()          # Check PDF health\")\n",
        "print(\"📚 show_help_and_usage()          # Complete guide\")\n",
        "print(\"📊 system_status()                # System information\")\n",
        "\n",
        "print(f\"\\n✨ Ready for processing! Choose a command above to get started.\")"
      ],
      "metadata": {
        "id": "6d6MNMTqpUAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa29d19-9b8e-4e14-9be3-6e2b1e2d8134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All imports successful!\n",
            "🕐 Session started: 2025-08-08 12:18:45 UTC\n",
            "👤 User: Ravi-katta-dev\n",
            "🎯 COMPLETE PDF SPLITTER v4.0 - FULLY LOADED!\n",
            "======================================================================\n",
            "🕐 System Time: 2025-08-08 12:22:52 UTC\n",
            "👤 Current User: Ravi-katta-dev\n",
            "🚀 Status: All systems operational\n",
            "======================================================================\n",
            "📊 SYSTEM STATUS REPORT\n",
            "==================================================\n",
            "🕐 Current Time: 2025-08-08 12:22:52 UTC\n",
            "👤 Current User: Ravi-katta-dev\n",
            "🐍 Python Environment: Google Colab\n",
            "📦 PyMuPDF Version: 1.26.3\n",
            "==================================================\n",
            "📁 Current Directory Analysis:\n",
            "   • Total files: 2\n",
            "   • PDF files: 0\n",
            "\n",
            "❌ No PDF files found\n",
            "💡 Upload a PDF file to get started\n",
            "\n",
            "💾 Memory Status:\n",
            "   • Available: 11.4 GB\n",
            "   • Usage: 9.9%\n",
            "\n",
            "💡 RECOMMENDATIONS:\n",
            "   🔸 Upload a PDF file first\n",
            "   🔸 Run show_help_and_usage() for guidance\n",
            "\n",
            "🎮 QUICK START COMMANDS:\n",
            "------------------------------\n",
            "🚀 quick_split_now()              # Fast processing\n",
            "🎮 run_interactive_mode()         # Step-by-step guidance\n",
            "🧪 test_comprehensive_analysis()  # Test all methods\n",
            "🔍 diagnose_pdf_issues()          # Check PDF health\n",
            "📚 show_help_and_usage()          # Complete guide\n",
            "📊 system_status()                # System information\n",
            "\n",
            "✨ Ready for processing! Choose a command above to get started.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_help_and_usage()"
      ],
      "metadata": {
        "id": "m0cm7ghenR0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8dd358-9f41-4d1d-940f-09731f4d039d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📚 COMPLETE PDF SPLITTER - HELP & USAGE GUIDE\n",
            "======================================================================\n",
            "🕐 Time: 2025-08-08 12:22:52 UTC\n",
            "👤 User: Ravi-katta-dev\n",
            "📱 Session: 20250808_124149\n",
            "======================================================================\n",
            "\n",
            "🎯 AVAILABLE FUNCTIONS:\n",
            "\n",
            "1. 🚀 QUICK PROCESSING:\n",
            "   quick_split_now()                    - Fast split with smart defaults\n",
            "   \n",
            "2. 🎮 INTERACTIVE MODE:\n",
            "   run_interactive_mode()               - Step-by-step guided processing\n",
            "   \n",
            "3. 🧠 COMPREHENSIVE ANALYSIS:\n",
            "   test_comprehensive_analysis()        - Test all detection methods\n",
            "   run_intelligent_split()              - Full multi-method processing\n",
            "   \n",
            "4. 📦 BATCH PROCESSING:\n",
            "   batch_process_pdfs()                 - Process multiple PDFs\n",
            "   \n",
            "5. 🔍 DIAGNOSTIC TOOLS:\n",
            "   diagnose_pdf_issues()                - Analyze PDF structure and issues\n",
            "   \n",
            "6. ℹ️ HELP & INFO:\n",
            "   show_help_and_usage()                - This help guide\n",
            "\n",
            "═══════════════════════════════════════════════════════════════════════\n",
            "\n",
            "🎯 RECOMMENDED WORKFLOW:\n",
            "\n",
            "For First-Time Users:\n",
            "1. Upload your PDF file\n",
            "2. Run: diagnose_pdf_issues()          # Check for any issues\n",
            "3. Run: test_comprehensive_analysis()   # See what methods work best\n",
            "4. Run: run_interactive_mode()         # Process with guidance\n",
            "\n",
            "For Quick Processing:\n",
            "1. Upload your PDF file\n",
            "2. Run: quick_split_now()              # Fast processing\n",
            "\n",
            "For Multiple Files:\n",
            "1. Upload multiple PDF files\n",
            "2. Run: batch_process_pdfs()           # Process all at once\n",
            "\n",
            "═══════════════════════════════════════════════════════════════════════\n",
            "\n",
            "🔧 DETECTION METHODS:\n",
            "\n",
            "📏 Line Detection:\n",
            "   - Finds actual vertical lines in your PDF\n",
            "   - Perfect for documents with visible dividers\n",
            "   - High accuracy for structured documents\n",
            "\n",
            "🧠 Content Analysis:\n",
            "   - Analyzes text density and distribution\n",
            "   - Good for documents without visible lines\n",
            "   - Works with natural content boundaries\n",
            "\n",
            "👁️ Visual Pattern Recognition:\n",
            "   - Recognizes visual layout patterns\n",
            "   - Detects column structures and alignments\n",
            "   - Useful for complex layouts\n",
            "\n",
            "📋 Document Structure Analysis:\n",
            "   - Understands document type and purpose\n",
            "   - Optimizes for exam papers, forms, etc.\n",
            "   - Context-aware processing\n",
            "\n",
            "🎯 Multi-Method Fusion:\n",
            "   - Combines all methods for best accuracy\n",
            "   - Highest confidence results\n",
            "   - Recommended for unknown document types\n",
            "\n",
            "═══════════════════════════════════════════════════════════════════════\n",
            "\n",
            "💡 TROUBLESHOOTING:\n",
            "\n",
            "❌ \"No PDF files found\":\n",
            "   - Upload a PDF file first\n",
            "   - Check file has .pdf extension\n",
            "   - Restart runtime if needed\n",
            "\n",
            "❌ \"Processing failed\":\n",
            "   - Run diagnose_pdf_issues() to check PDF\n",
            "   - Try different detection method\n",
            "   - Check if PDF is password protected\n",
            "\n",
            "❌ \"Download failed\":\n",
            "   - File is still processed locally\n",
            "   - Try downloading manually\n",
            "   - Check internet connection\n",
            "\n",
            "❌ \"Low confidence detection\":\n",
            "   - PDF might have unusual layout\n",
            "   - Try manual ratio adjustment\n",
            "   - Use visual inspection\n",
            "\n",
            "═══════════════════════════════════════════════════════════════════════\n",
            "\n",
            "🎓 TIPS FOR BEST RESULTS:\n",
            "\n",
            "✅ PDF Quality:\n",
            "   - Use high-quality, text-based PDFs\n",
            "   - Avoid heavily compressed files\n",
            "   - Ensure text is selectable\n",
            "\n",
            "✅ Document Type:\n",
            "   - Works best with structured documents\n",
            "   - Exam papers, forms, and reports ideal\n",
            "   - Two-column layouts process excellently\n",
            "\n",
            "✅ File Size:\n",
            "   - Files under 50MB process fastest\n",
            "   - Large files may take longer\n",
            "   - Consider batch processing for multiple files\n",
            "\n",
            "✅ Split Ratios:\n",
            "   - 40-60% typically work best\n",
            "   - Extreme ratios (20% or 80%) may indicate issues\n",
            "   - Trust high-confidence detections\n",
            "\n",
            "═══════════════════════════════════════════════════════════════════════\n",
            "\n",
            "🆘 SUPPORT:\n",
            "\n",
            "If you encounter issues:\n",
            "1. Run diagnose_pdf_issues() first\n",
            "2. Check the troubleshooting section above\n",
            "3. Try different processing methods\n",
            "4. Consider manual ratio adjustment\n",
            "\n",
            "For best results with your exam papers:\n",
            "- Use quick_split_now() for simple cases\n",
            "- Use run_interactive_mode() for guidance\n",
            "- Use test_comprehensive_analysis() to verify detection\n",
            "\n",
            "═══════════════════════════════════════════════════════════════════════\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_interactive_mode()"
      ],
      "metadata": {
        "id": "ax4ER7QCDtUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_comprehensive_analysis()"
      ],
      "metadata": {
        "id": "7H8AVLzvD1CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "e4e19417abd74540b2a2adfad7f8f734",
            "810418fd60a24b6ba145acf4c587a88e",
            "06f086c2109b4a91bea3bd7a27eefdb3",
            "54286564b8dc4f22919b0c3b67ff939b",
            "fb94dfc626834c4daa6e3a759b5c3365",
            "ea954cb62a5c4cf99139e2d184c9e77d",
            "a1d3aad9cefc4627b347c64fd7288101",
            "22e6927063304d18b0004bbc0cd52da7",
            "347a560f43874bcd9baecd398bc85fd3",
            "b2c5ab019c9d4cb6aa7375b2adf4942e",
            "2c7527778b6f4f7db88e71b1599b6b29",
            "a15801ac8b644a0d8a4eb55e286bcd86",
            "adf739016cd543419c2f8520a153f124",
            "af477ceb27a4454b852e1a35f75ec8cb",
            "1283aa92f1174212b6f6f659bb9fb56b",
            "e965b2f2a87d4fea9377d5b1f89721d7",
            "dec8175247c34d799f583523406514a2"
          ]
        },
        "id": "vqCRFuY6nEFu",
        "outputId": "c3c720d9-db59-4942-eee0-e1be9bbeb381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 INTELLIGENT PDF SPLITTER v3.0\n",
            "============================================================\n",
            "🧠 AI-Powered Content-Aware PDF Splitting for Google Colab\n",
            "============================================================\n",
            "🎯 Intelligent PDF Splitter initialized!\n",
            "🎯 Intelligent PDF Splitter Configuration\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h3>🎯 Configuration Options</h3>'), Dropdown(description='Split Mode:', options=(('…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4e19417abd74540b2a2adfad7f8f734"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📁 Upload your PDF files:\n",
            "💡 The AI will analyze content layout automatically\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-919675cf-a607-4474-be95-39994ab3e233\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-919675cf-a607-4474-be95-39994ab3e233\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "main_intelligent()  # Interactive mode with UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vpz_0sRhoP1o",
        "outputId": "008d9014-cc34-4344-db39-7a951ad0d269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 QUICK FIX MODE\n",
            "==============================\n",
            "📁 Found existing PDF files: ['SPLIT_Tech Practice1-80.pdf', 'Tech Practice1-80.pdf']\n",
            "📥 Attempting to download: SPLIT_Tech Practice1-80.pdf\n",
            "📥 Downloading: SPLIT_Tech Practice1-80.pdf (attempt 1)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_5fa8041e-7bbe-44a4-b777-ea0f60a3b208\", \"SPLIT_Tech Practice1-80.pdf\", 3588133)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Download successful!\n"
          ]
        }
      ],
      "source": [
        "quick_fix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5QfZvx0mnnI",
        "outputId": "a72b37dd-ce3e-49da-bf1a-39c225d0fb9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Setting up Enhanced PDF Splitter...\n",
            "==================================================\n",
            "\n",
            "📦 Installing dependencies...\n",
            "📦 Installing pymupdf...\n",
            "✅ pymupdf installed successfully!\n",
            "📦 Installing Pillow...\n",
            "✅ Pillow installed successfully!\n",
            "✅ tqdm already installed\n",
            "\n",
            "✅ All dependencies installed successfully!\n",
            "🎉 Ready to load the PDF Splitter!\n",
            "\n",
            "==================================================\n",
            "Next: Run the second cell to load the PDF Splitter code\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# 🚀 ENHANCED PDF SPLITTER - GOOGLE COLAB SETUP\n",
        "# =============================================================================\n",
        "# Run this cell first to install all dependencies and set up the environment\n",
        "\n",
        "print(\"🔧 Setting up Enhanced PDF Splitter...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install package with progress indication\"\"\"\n",
        "    try:\n",
        "        __import__(package.replace('-', '_').split('[')[0])\n",
        "        print(f\"✅ {package} already installed\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"📦 Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"✅ {package} installed successfully!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to install {package}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Required packages\n",
        "packages = [\n",
        "    \"pymupdf\",      # PDF processing\n",
        "    \"Pillow\",       # Image processing\n",
        "    \"tqdm\",         # Progress bars\n",
        "]\n",
        "\n",
        "print(\"\\n📦 Installing dependencies...\")\n",
        "all_installed = True\n",
        "for package in packages:\n",
        "    if not install_package(package):\n",
        "        all_installed = False\n",
        "\n",
        "if all_installed:\n",
        "    print(\"\\n✅ All dependencies installed successfully!\")\n",
        "    print(\"🎉 Ready to load the PDF Splitter!\")\n",
        "else:\n",
        "    print(\"\\n❌ Some packages failed to install. Please try restarting the runtime.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Next: Run the second cell to load the PDF Splitter code\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quick_split_now()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949,
          "referenced_widgets": [
            "5451c7d284734fa4ab2e944729622134",
            "00fec06b70fe4bb3ae452e7f3cbf949b",
            "b6e8b20605f14e40bddc74e750f8c8b6",
            "0bb7cca078de471eb83689069ee7c2f5",
            "2bc369cddae44763bfc9826b067a1bb7",
            "4e07a56bf48a4cc89fe59d64fb5e517e",
            "801ab21ac196495ca6c938035b3abed4",
            "3bc50e72a4d7429798098150b1dc068f",
            "fb627f370a2d4998b6a8ad72fcdfbb7d",
            "bc5e3d6cf70444309afd84cc1e272f66",
            "bd4a0c95b93244f791c905e92c85f297"
          ]
        },
        "id": "I_zRv7SUqRR0",
        "outputId": "972e34fe-546a-4655-894d-1ce5ae0aa871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚡ QUICK SPLIT - FAST PROCESSING\n",
            "==================================================\n",
            "🕐 Time: 2025-08-08 12:22:52 UTC\n",
            "👤 User: Ravi-katta-dev\n",
            "⚡ Fast processing with smart defaults\n",
            "==================================================\n",
            "📁 Processing: Tech Practice1-80.pdf\n",
            "📊 File size: 3.53 MB\n",
            "🎯 Complete PDF Splitter v4.0 initialized!\n",
            "📱 Session ID: 20250808_124712\n",
            "🚀 Quick processing...\n",
            "🔍 Step 1: Comprehensive PDF Analysis\n",
            "==================================================\n",
            "🎯 Running comprehensive multi-method analysis...\n",
            "📏 Method 1: Vertical line detection...\n",
            "📏 Analyzing 10 pages for vertical lines...\n",
            "🧠 Method 2: Content layout analysis...\n",
            "🧠 Analyzing content layout from 5 pages...\n",
            "👁️ Method 3: Visual pattern recognition...\n",
            "📋 Method 4: Document structure analysis...\n",
            "🔄 Combining all analysis methods...\n",
            "\n",
            "📊 Analysis Results:\n",
            "   • Detection method: multi_method_combined\n",
            "   • Optimal split ratio: 54.3%\n",
            "   • Detection confidence: 78.4%\n",
            "   • Line detection confidence: 86.0%\n",
            "   • Content analysis confidence: 50.0%\n",
            "   • Methods agreement: 99.3%\n",
            "\n",
            "✂️ Step 2: Applying Split at 54.3%\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "📄 Processing:   0%|          | 0/80 [00:00<?, ?page/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5451c7d284734fa4ab2e944729622134"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Step 3: Saving Results\n",
            "==================================================\n",
            "✅ Processing Complete!\n",
            "\n",
            "📊 Results Summary:\n",
            "   • Input file: Tech Practice1-80.pdf\n",
            "   • Output file: QUICK_SPLIT_Tech Practice1-80_124712.pdf\n",
            "   • Pages processed: 80/80\n",
            "   • Pages created: 160\n",
            "   • Output size: 3.42 MB\n",
            "   • Processing time: 1.08 seconds\n",
            "   • Speed: 74.2 pages/second\n",
            "   • Split ratio used: 54.3%\n",
            "   • Detection confidence: 78.4%\n",
            "   • Success rate: 100.0%\n",
            "✅ Done! Downloading QUICK_SPLIT_Tech Practice1-80_124712.pdf...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05ec4c83-4759-4d46-a09d-1abf98b350e0\", \"QUICK_SPLIT_Tech Practice1-80_124712.pdf\", 3589733)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 Success! Your split PDF has been downloaded.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdMzEycI7m3Cx9/VI32nTZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4e19417abd74540b2a2adfad7f8f734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_810418fd60a24b6ba145acf4c587a88e",
              "IPY_MODEL_06f086c2109b4a91bea3bd7a27eefdb3",
              "IPY_MODEL_54286564b8dc4f22919b0c3b67ff939b",
              "IPY_MODEL_fb94dfc626834c4daa6e3a759b5c3365",
              "IPY_MODEL_ea954cb62a5c4cf99139e2d184c9e77d"
            ],
            "layout": "IPY_MODEL_a1d3aad9cefc4627b347c64fd7288101"
          }
        },
        "810418fd60a24b6ba145acf4c587a88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e6927063304d18b0004bbc0cd52da7",
            "placeholder": "​",
            "style": "IPY_MODEL_347a560f43874bcd9baecd398bc85fd3",
            "value": "<h3>🎯 Configuration Options</h3>"
          }
        },
        "06f086c2109b4a91bea3bd7a27eefdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "🤖 Intelligent Auto-Split (Recommended)",
              "📄 Vertical Split (Left/Right)",
              "📄 Horizontal Split (Top/Bottom)",
              "🎛️ Custom Vertical Split",
              "🎛️ Custom Horizontal Split"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Split Mode:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_b2c5ab019c9d4cb6aa7375b2adf4942e",
            "style": "IPY_MODEL_2c7527778b6f4f7db88e71b1599b6b29"
          }
        },
        "54286564b8dc4f22919b0c3b67ff939b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": true,
            "description": "Custom Ratio:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a15801ac8b644a0d8a4eb55e286bcd86",
            "max": 0.9,
            "min": 0.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".0%",
            "step": 0.05,
            "style": "IPY_MODEL_adf739016cd543419c2f8520a153f124",
            "value": 0.5
          }
        },
        "fb94dfc626834c4daa6e3a759b5c3365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Show detailed content analysis",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_af477ceb27a4454b852e1a35f75ec8cb",
            "style": "IPY_MODEL_1283aa92f1174212b6f6f659bb9fb56b",
            "value": true
          }
        },
        "ea954cb62a5c4cf99139e2d184c9e77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e965b2f2a87d4fea9377d5b1f89721d7",
            "placeholder": "​",
            "style": "IPY_MODEL_dec8175247c34d799f583523406514a2",
            "value": "\n        <div style='background-color: #e8f4fd; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n            <b>🤖 Intelligent Mode Features:</b><br>\n            • Analyzes text layout and content distribution<br>\n            • Finds natural split points in content<br>\n            • Avoids cutting through text blocks<br>\n            • Optimizes for content preservation<br>\n            • Works great for exam papers, documents, and forms\n        </div>\n        "
          }
        },
        "a1d3aad9cefc4627b347c64fd7288101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e6927063304d18b0004bbc0cd52da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347a560f43874bcd9baecd398bc85fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2c5ab019c9d4cb6aa7375b2adf4942e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c7527778b6f4f7db88e71b1599b6b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "120px"
          }
        },
        "a15801ac8b644a0d8a4eb55e286bcd86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf739016cd543419c2f8520a153f124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "120px",
            "handle_color": null
          }
        },
        "af477ceb27a4454b852e1a35f75ec8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1283aa92f1174212b6f6f659bb9fb56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "e965b2f2a87d4fea9377d5b1f89721d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec8175247c34d799f583523406514a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5451c7d284734fa4ab2e944729622134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00fec06b70fe4bb3ae452e7f3cbf949b",
              "IPY_MODEL_b6e8b20605f14e40bddc74e750f8c8b6",
              "IPY_MODEL_0bb7cca078de471eb83689069ee7c2f5"
            ],
            "layout": "IPY_MODEL_2bc369cddae44763bfc9826b067a1bb7"
          }
        },
        "00fec06b70fe4bb3ae452e7f3cbf949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e07a56bf48a4cc89fe59d64fb5e517e",
            "placeholder": "​",
            "style": "IPY_MODEL_801ab21ac196495ca6c938035b3abed4",
            "value": "📄 Processing: 100%"
          }
        },
        "b6e8b20605f14e40bddc74e750f8c8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc50e72a4d7429798098150b1dc068f",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb627f370a2d4998b6a8ad72fcdfbb7d",
            "value": 80
          }
        },
        "0bb7cca078de471eb83689069ee7c2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc5e3d6cf70444309afd84cc1e272f66",
            "placeholder": "​",
            "style": "IPY_MODEL_bd4a0c95b93244f791c905e92c85f297",
            "value": " 80/80 [00:00&lt;00:00, 127.54page/s, Split=54.3%, Success=80/80]"
          }
        },
        "2bc369cddae44763bfc9826b067a1bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e07a56bf48a4cc89fe59d64fb5e517e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801ab21ac196495ca6c938035b3abed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc50e72a4d7429798098150b1dc068f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb627f370a2d4998b6a8ad72fcdfbb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc5e3d6cf70444309afd84cc1e272f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd4a0c95b93244f791c905e92c85f297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}